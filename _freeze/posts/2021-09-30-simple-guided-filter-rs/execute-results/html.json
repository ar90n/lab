{
  "hash": "125cbde693100c127d2b7c4b28a146ef",
  "result": {
    "markdown": "---\naliases:\n- /ImageProcessing/Rust/2021/09/30/simple-guided-filter-rs\ncategories:\n- Rust\n- 画像処理\ndate: '2021-09-30'\noutput-file: 2021-09-30-simple-guided-filter-rs.html\ntitle: \"Rust\\u306B\\u3088\\u308B\\u30B7\\u30F3\\u30D7\\u30EB\\u306AGuidedFilter\\u306E\\u5B9F\\\n  \\u88C5\"\ntoc: true\nimage: /assets/img/2021-09-30-simple-guided-filter-rs/media/output.jpg\n---\n\n\n## はじめに\n高速なエッジ保持平滑化フィルタとしてGuidedFilter[@he2012guided]が広く知られています．この記事では輝度信号に限定したシンプルな実装を紹介します．なお，実装にはRustと[image](\"https://github.com/image-rs/image\")クレートを用いました．\n\n## やったこと\n\n * GuidedFilterを用いたエッジ保持平滑化フィルタを実装\n\n## GuidedFilterについて\n\nGuidedFilterはガイド信号$\\bf{I}$の１次式で入力信号$\\bf{p}$を近似することで出力信号$\\bf{q}$を得ます．また，このガイド信号の選択により様々な応用が考案されています．今回紹介するエッジ保持平滑化フィルタはその中の一つです．\n\nそれでは，実際に出力信号を得るための方法について述べていきます．まず，$\\bf{q}$と$\\bf{I}$との関係を以下のように定義します．\n\n$$\n\\begin{aligned}\nq_{i} & = a_{k} I_{i} + b_{k} \\ ,\\forall i \\in \\omega_{k} \\\\ \n\\end{aligned}\n$$\n\nここで，$i$は画素のインデックスを，$k$はウィンドウ中心画素のインデックスを，$\\omega_{k}$はウィンドウをそれぞれ表します．\n\n\n次に，$p$と$q$との関係について考えます．ここでノイズ$n$を用いると以下のように表現することができます．\n\n$$\n\\begin{aligned}\nq_{i} & = p_{i} - n_{i} \\\\\n   & = a_{k} I_{i} + b_{k}\n\\end{aligned}\n$$\n\nそして，$q$で$p$をより良く近似するため，以下の評価関数の最小化を考えます．\n\n$$\n\\begin{aligned}\nE\\left(a_{k}, b_{k}\\right) & = \\sum_{i \\in \\omega_{k}} \\left(\\left(a_{k}I_{i} + b_{k} - p_{i}\\right)^{2} + \\epsilon a_{k}^{2}\\right) \\\\\n\\end{aligned}\n$$\n\nこの式において，$\\epsilon a_{k}^{2}$で表される項は，$a_{k}$の正則化を目的としたものです．この項はリッジ回帰に用いられる正則化項と同様のモチベーションで導入されています．\n\nそれでは，$E\\left(a_{k}, b_{k}\\right)$を$a_{k}$および$b_{k}$で偏微分して最適な$a_{k}$と$b_{k}$を求めていきます．最初に$b_{k}$について考えます．\n\n$$\n\\begin{aligned}\n\\frac{\\partial}{\\partial b_{k}} E\\left(a_{k}, b_{k}\\right) & = 2\\sum_{i \\in \\omega_{k}} \\left(a_{k}I_{i} + b_{k} - p_{i}\\right) \\\\\n&= 0 \\\\\nb_{k} &= \\frac{1}{\\left| \\omega_{k} \\right|} \\sum_{i \\in \\omega_{k}} p_{i} - \\frac{a_{k}}{\\left| \\omega_{k} \\right|}\\sum_{i \\in \\omega_{k}} I_{i}\\\\\n\\end{aligned}\n$$\n\nここで，$\\bar{p_{k}} = \\frac{1}{\\left| \\omega_{k} \\right|} \\sum_{i \\in \\omega_{k}} p_{i}$, $\\mu_{k} = \\frac{1}{\\left| \\omega_{k} \\right|}\\sum_{i \\in \\omega_{k}} I_{i}$ とすると，\n\n$$\n\\begin{aligned}\nb_{k} &= \\bar{p_{k}} - a_{k} \\mu_{k} \n\\end{aligned}\n$$\n\n次に$a_{k}$について考えます．\n\n$$\n\\begin{aligned}\n\\frac{\\partial}{\\partial a_{k}} E\\left(a_{k}, b_{k}\\right) & = \\frac{\\partial}{\\partial a_{k}} \\sum_{i \\in \\omega_{k}} \\left(\\left(a_{k}I_{i} + b_{k} - p_{i}\\right)^{2} + \\epsilon a_{k}^{2}\\right)\\\\\n&=   \\frac{\\partial}{\\partial a_{k}} \\sum_{i \\in \\omega_{k}} \\left(\\left(a_{k}I_{i} + \\bar{p_{k}} - a_{k} \\mu_{k}  - p_{i}\\right)^{2} + \\epsilon a_{k}^{2}\\right)\\\\\n&=   \\frac{\\partial}{\\partial a_{k}} \\sum_{i \\in \\omega_{k}} \\left(\\left(a_{k} \\left( I_{i}  -\\mu_{k}\\right) + \\bar{p_{k}} - p_{i}\\right)^{2} + \\epsilon a_{k}^{2}\\right)\\\\\n&= 2\\sum_{i \\in \\omega_{k}} \\left(\\left(a_{k} \\left( I_{i}  -\\mu_{k}\\right) + \\bar{p_{k}} - p_{i}\\right)\\left( I_{i}  -\\mu_{k}\\right) + \\epsilon a_{k}\\right)\\\\\n&= 2a_{k} \\sum_{i \\in \\omega_{k}} \\left( I_{i}  -\\mu_{k}\\right)^{2}   - 2 \\sum_{i \\in \\omega_{k}} p_{i}I_{i} + 2 \\mu_{k} \\sum_{i \\in \\omega_{k}} p_{i} + 2 \\bar{p_{k}} \\sum_{i \\in \\omega_{k}} I_{i} -2 \\bar{p_{k}} \\mu_{k} \\left|\\omega_{k}\\right| + 2 \\epsilon a_{k} \\left| \\omega_{k} \\right| \\\\\n&= 2a_{k} \\sigma_{k}^{2} \\left|\\omega_{k}\\right|  - 2 \\sum_{i \\in \\omega_{k}} p_{i}I_{i} + 2 \\mu_{k}\\bar{p_{k}}\\left|\\omega_{k}\\right|   + 2 \\bar{p_{k}} \\mu_{k}\\left|\\omega_{k}\\right| -2 \\bar{p_{k}} \\mu_{k} \\left|\\omega_{k}\\right| + 2 \\epsilon a_{k} \\left| \\omega_{k} \\right| \\\\\n&= 0 \\\\\na_{k} &= \\frac{ \\frac{1}{\\left|\\omega_{k}\\right|} \\sum_{i \\in \\omega_{k}} p_{i}I_{i} - \\bar{p_{k}} \\mu_{k} }{\\sigma_{k}^{2} + \\epsilon }\n\\end{aligned}\n$$\n\nここで，再度$q_{i}$について考えます．$q_{i}$は$a_{k}$及び$b_{k}$に依存していますが，これらの値はウィンドウ$\\omega_{k}$の中心座標$k$に対して変化します．従って，$q_{i}$を一意に定めることはできません．そこで，$q_{i}$に影響を及ぼす$\\omega_{k}$対して平均値を計算します．\n\n$$\n\\begin{aligned}\nq_{i} & = \\frac{1}{\\left|\\omega_{i}\\right|} \\sum_{k \\in \\omega_{i}} \\left(a_{k} I_{i} + b_{k}\\right) \\\\\n&= \\left(\\frac{1}{\\left| \\omega_{i} \\right|} \\sum_{k \\in \\omega_{i}}a_{k} \\right)I_{i} + \\frac{1}{\\left| \\omega_{i} \\right|} \\sum_{k \\in \\omega_{i}}b_{k} \\\\\n&= \\bar{a_{i}} I_{I} + \\bar{b_{i}}\n\\end{aligned}\n$$\n\n## Rustによる実装\n\n それでは，実際にRustでGuidedFilterを実装していきます．今回，以下のクレートを使用します．\n \n * [image](\"https://github.com/image-rs/image\")\n * [num-traits](\"https://crates.io/crates/num-traits\")\n * [base64](\"https://crates.io/crates/base64\")\n \n \n `image` は画像の読み書き及びデータ表現に，`num-traits` は画像データ型から計算用のデータ型への変換に，`base64`はNotebook上への画像出力にそれぞれ用いました．\n\nまず初めに必要なクレートを導入します．\n\n::: {.cell vscode='{\"languageId\":\"rust\"}' execution_count=2}\n``` {.rust .cell-code}\n:dep image \n:dep num-traits\n:dep base64\n//above line is magic for adding crate\n\nuse image::{GenericImageView, ImageBuffer, Luma, Pixel, Primitive};\nuse num_traits::NumCast;\n```\n:::\n\n\n次にNotebook上への画像出力機能を実装します．詳細は[以前の記事](\"https://lab.ar90n.net/rust/jupyter/2020/11/15/rust-on-nodebook-with-evcxr-jupyter.html\")を参考にしてください．\n\n::: {.cell vscode='{\"languageId\":\"rust\"}' execution_count=3}\n``` {.rust .cell-code}\nextern crate image;\nextern crate base64;\npub trait EvcxrResult {fn evcxr_display(&self);}\nimpl EvcxrResult for ImageBuffer<Luma<u8>, Vec<u8>> {\n    fn evcxr_display(&self) {\n        let mut buffer = Vec::new();\n        image::codecs::jpeg::JpegEncoder::new(&mut buffer).encode(&**self, self.width(), self.height(),\n            image::ColorType::L8).unwrap();\n        let img = base64::encode(&buffer);\n        println!(\"EVCXR_BEGIN_CONTENT image/jpeg\\n{}\\nEVCXR_END_CONTENT\", img);        \n    }\n}\n```\n:::\n\n\n次にあると便利な雑多な関数を実装します．ここでは，所望のデータ型を`Subpixel`とした`Pixel`型を取得する`cast_subpixel` と スケールを調整した$\\epsilon$ を計算する`calc_eps` を実装します．論文中では画像データを$0 \\sim 1$に正規化した状態で取り扱っています．今回の実装では，画像データを$0 \\sim 255$ の範囲で取り扱うため，`calc_eps` で$\\epsilon$の値を適切にスケーリングします．\n\n::: {.cell vscode='{\"languageId\":\"rust\"}' execution_count=4}\n``` {.rust .cell-code}\nfn cast_subpixel<S, T>(pixel: &Luma<S>) -> Luma<T>\nwhere\n    S: Primitive,\n    T: Primitive,\n{\n    let Luma([data]) = *pixel;\n    Luma([NumCast::from(data).unwrap(); 1])\n}\n\n\nfn cals_eps(eps: f64) -> f64 {\n    let eps = 255.0 * eps;\n    eps * eps\n}\n```\n:::\n\n\n次に２次元平滑化処理を行う`mean2d` を実装します．2次元平滑化処理は\n\n1. x方向移動平均フィルタ\n1. 転置\n1. x方向移動平均フィルタ\n1. 転置\n\nという処理で実現しています．\n\n::: {.cell vscode='{\"languageId\":\"rust\"}' execution_count=5}\n``` {.rust .cell-code}\nfn mean2d<I, S>(image: &I, r: u32) -> ImageBuffer<Luma<f64>, Vec<f64>>\nwhere\n    I: GenericImageView<Pixel = Luma<S>>,\n    S: Primitive + 'static,\n{\n    fn get_luma_as_f64<I, S>(image: &I, x: u32, y: u32) -> f64\n    where\n        I: GenericImageView<Pixel = Luma<S>>,\n        S: Primitive + 'static,\n    {\n        let Luma(data) = image.get_pixel(x, y);\n        NumCast::from(data[0]).unwrap()\n    }\n\n    fn calc_mean(head_value: f64, tail_value: f64, r: u32) -> f64 {\n        let den = 2.0 * r as f64 + 1.0;\n        let num = head_value - tail_value;\n        num / den\n    }\n\n    fn meand2d_tr<I, S>(image: &I, r: u32) -> ImageBuffer<Luma<f64>, Vec<f64>>\n    where\n        I: GenericImageView<Pixel = Luma<S>>,\n        S: Primitive + 'static,\n    {\n        let (width, height) = image.dimensions();\n        let mut result = ImageBuffer::new(height, width);\n\n        for y in 0..height {\n            let mut head_x: u32 = 0;\n            let mut mid_x: u32 = 0;\n            let mut tail_x: u32 = 0;\n            let mut acc_head_x: f64 = 0.0;\n            let mut acc_tail_x: f64 = 0.0;\n\n            while mid_x < width {\n                if head_x < width {\n                    acc_head_x += get_luma_as_f64(image, head_x, y);\n                    head_x += 1;\n                }\n                if r < mid_x {\n                    acc_tail_x += get_luma_as_f64(image, tail_x, y);\n                    tail_x += 1;\n                }\n                if r <= head_x {\n                    let pixel = Luma([calc_mean(acc_head_x, acc_tail_x, r); 1]);\n                    result.put_pixel(y, mid_x, pixel);\n                    mid_x += 1;\n                }\n            }\n        }\n\n        result\n    }\n\n    meand2d_tr(&meand2d_tr(image, r), r)\n}\n```\n:::\n\n\n実際にGuidedFilterの処理を行う関数`guided_filter`です．今回はエッジ保持平滑化フィルタのみを対象としているため，$I = p$（ガイド信号は入力信号と等しい）としています．また，`r`はウィンドウ領域の半径を，`eps`は$\\epsilon$をそれぞれ表します．\n\n::: {.cell vscode='{\"languageId\":\"rust\"}' execution_count=6}\n``` {.rust .cell-code}\nfn guided_filter<I, S>(image: &I, r: u32, eps: f64) -> ImageBuffer<Luma<u8>, Vec<u8>>\nwhere\n    I: GenericImageView<Pixel = Luma<S>>,\n    S: Primitive + 'static,\n{\n    let eps = cals_eps(eps);\n    let i = image;\n    let mean_i = mean2d(i, r);\n\n    let (w, h) = i.dimensions();\n    let ii = ImageBuffer::from_fn(w, h, |x, y| {\n        cast_subpixel(&i.get_pixel(x, y)).map(|v: f64| v * v)\n    });\n    let corr_i = mean2d(&ii, r);\n\n    let var_i = ImageBuffer::from_fn(w, h, |x, y| {\n        mean_i\n            .get_pixel(x, y)\n            .map2(corr_i.get_pixel(x, y), |m, c| c - m * m)\n    });\n\n    let a = ImageBuffer::from_fn(w, h, |x, y| {\n        var_i.get_pixel(x, y).map_without_alpha(|v| v / (v + eps))\n    });\n\n    let b = ImageBuffer::from_fn(w, h, |x, y| {\n        mean_i\n            .get_pixel(x, y)\n            .map2(a.get_pixel(x, y), |m, a| (1.0 - a) * m)\n    });\n\n    let mean_a = mean2d(&a, r);\n    let mean_b = mean2d(&b, r);\n\n    let q = ImageBuffer::from_fn(w, h, |x, y| {\n        let i_v: f64 = {\n            let Luma([data]) = i.get_pixel(x, y);\n            NumCast::from(data).unwrap()\n        };\n\n        mean_a\n            .get_pixel(x, y)\n            .map2(mean_b.get_pixel(x, y), |a, b| a * i_v + b)\n    });\n    \n    ImageBuffer::from_fn(w, h, |x, y| -> Luma<u8> {\n        cast_subpixel(q.get_pixel(x, y))\n    })\n}\n```\n:::\n\n\n## 実行結果\n\n入力信号は以下のとおりです．\n\n::: {.cell vscode='{\"languageId\":\"rust\"}' execution_count=7}\n``` {.rust .cell-code}\nlet img = image::open(\"../assets/img/2021-09-30-simple-guided-filter-rs/media/input.jpg\").unwrap().to_luma8();\nimg\n```\n\n::: {.cell-output .cell-output-display execution_count=26}\n![](2021-09-30-simple-guided-filter-rs_files/figure-html/cell-7-output-1.jpeg){}\n:::\n:::\n\n\n### r=18, eps=0.1^2\n\n::: {.cell vscode='{\"languageId\":\"rust\"}' execution_count=8}\n``` {.rust .cell-code}\nguided_filter(&img, 18, 0.1)\n```\n\n::: {.cell-output .cell-output-display execution_count=27}\n![](2021-09-30-simple-guided-filter-rs_files/figure-html/cell-8-output-1.jpeg){}\n:::\n:::\n\n\n### r=18, eps=0.4^2\n\n::: {.cell vscode='{\"languageId\":\"rust\"}' execution_count=9}\n``` {.rust .cell-code}\nguided_filter(&img, 18, 0.4)\n```\n\n::: {.cell-output .cell-output-display execution_count=28}\n![](2021-09-30-simple-guided-filter-rs_files/figure-html/cell-9-output-1.jpeg){}\n:::\n:::\n\n\n### r=18, eps=0.8^2\n\n::: {.cell vscode='{\"languageId\":\"rust\"}' execution_count=10}\n``` {.rust .cell-code}\nguided_filter(&img, 18, 0.8)\n```\n\n::: {.cell-output .cell-output-display execution_count=29}\n![](2021-09-30-simple-guided-filter-rs_files/figure-html/cell-10-output-1.jpeg){}\n:::\n:::\n\n\n## 参考\n::: {#refs}\n:::\n\n",
    "supporting": [
      "2021-09-30-simple-guided-filter-rs_files"
    ],
    "filters": [],
    "includes": {}
  }
}