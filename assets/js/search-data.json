{
  
    
        "post0": {
            "title": "XG-C100Cを追加してオンボードNICとブリッジ接続する",
            "content": "はじめに . Ubuntu 22.04で運用している開発用マシンにXG-C100Cを追加した記録です。 最終的に以下のような環境を構築します。 . ┌───────────────┐ ┌──────────────┐ ┌────────────────┐ │ │ │ │ │ │ │ │ 10.0.0.100/24 │ │ Dynamic │ │ │ MacBook Pro ├─────────────────────┤ Dev Server ├──────────────┤ Home Network │ │ │ │ │ │ │ │ │ │ │ │ │ └───────────────┘ └──────────────┘ └────────────────┘ . やったこと . Ubuntu22.04にXG-C100Cを導入 | 既存のNIC（オンボード）とXG-C100Cとの間をブリッジ接続 | . XG-C100Cの導入 . ASUSのサイトにあるドライバはバージョンが古い（5.0.3.3）ため私の環境（kernel 5.15.0-43）でコンパイルすることができませんでした。 そこで、 MarvellのダウンロードページからAQC107Cを選択してドライバを取得します。 . ダウンロード完了後、以下のように指示通り作業を行うとドライバを導入します。 . $ unzip Marvell_Linux_2.5.5.zip Archive: Marvell_Linux_2.5.5.zip creating: 05-23-22_Marvell_Linux_2.5.5/ inflating: 05-23-22_Marvell_Linux_2.5.5/atlantic-2.5.5.0-1.noarch.rpm extracting: 05-23-22_Marvell_Linux_2.5.5/atlantic.tar.gz inflating: 05-23-22_Marvell_Linux_2.5.5/README.txt inflating: 05-23-22_Marvell_Linux_2.5.5/Release_Notes_Linux_2.5.5.txt $ cd 05-23-22_Marvell_Linux_2.5.5 $ tar -zxf atlantic.tar.gz $ sudo ./dkms.sh install . 追加したNICの名称を確認します。正しい方法がわからないので、dmesg からそれっぽいものを持ってきます。 今回追加したNICはenp4s0という名称が付けられているようです。 . $ sudo dmesg| grep atlantic [ 2.502420] atlantic 0000:04:00.0: enabling device (0000 -&gt; 0002) [ 2.540366] atlantic: Detect ATL2FW 1030012 [ 5.859800] atlantic 0000:04:00.0 enp4s0: renamed from eth1 [ 17.700034] atlantic 0000:04:00.0 enp4s0: atlantic: link change old 0 new 1000 . NIC間のブリッジ接続 . ‘/etc/netplan/00-installer-config.yaml’を修正して既存のNIC(eno1)とブリッジ接続します。 . $ cat /etc/netplan/00-installer-config.yaml # This is the network config written by &#39;subiquity&#39; network: ethernets: eno1: {} enp4s0: {} bridges: br0: interfaces: - eno1 - enp4s0 dhcp4: true version: 2 . MacBook Pro &lt;-&gt; Home Network間の通信を透過的に行うためufwを設定します。 . $ sudo ufw allow from 10.0.0.0/24 . /etc/default/ufw ufw.orgも以下のように修正します。 . $ diff /etc/default/ufw ufw.org 19c19 &lt; DEFAULT_FORWARD_POLICY=&quot;ACCEPT&quot; &gt; DEFAULT_FORWARD_POLICY=&quot;DROP&quot; . 参考 . Marvell Drivers | Netplan reference | .",
            "url": "https://lab.ar90n.net/ubuntu/2022/08/12/xg-c100c-in-ubuntu-server.html",
            "relUrl": "/ubuntu/2022/08/12/xg-c100c-in-ubuntu-server.html",
            "date": " • Aug 12, 2022"
        }
        
    
  
    
        ,"post1": {
            "title": "Goで類似ベクトルを検索する",
            "content": "はじめに . 類似ベクトル検索を実現する代表的な実装にAnnoyがあります． 今回，Goの修練としてAnnoyの一部機能をGoで再実装しました． . https://github.com/ar90n/countrymaam . GitHub - ar90n/countrymaam: Plain ann-search implementation with Go Plain ann-search implementation with Go. Contribute to ar90n/countrymaam development by creating an account on GitHub. github.com やったこと . kd-treeベースの探索アルゴリズムを実装 | random projection treeベースの探索アルゴリズムを実装 | ann-benchmarksにてベンチマークを測定 | . Annoyの詳細 . Annoyの詳細については以下のページが大変勉強になりました． . https://techblog.zozo.com/entry/annoy-explanation . 近傍探索ライブラリ「Annoy」のコード詳解 - ZOZO TECH BLOG はじめまして、ZOZO研究所福岡の家富です。画像検索システムのインフラ、機械学習まわりを担当しています。 今回は画像検索システムでお世話になっているAnnoyについてじっくり紹介したいと思います。 目次 目次 Annoyについて 近傍探索について Annoyのソースコードを読むときのポイント AnnoyIndexというクラスのインスタンスを作る インストール過程について PythonのC/C++拡張 Annoyの実装 1. add_item 2. build 3. get_nns_by_vector 4. build再考 他に問題となる点について CPU依存部分 ディスクかメモリか まとめ さ… techblog.zozo.com 個人的には探索時のノードの取り扱い方が特に面白いと思ったので，そこの部分について少しだけ補足をしたいと思います． . 上記ページでも解説されている通り，探索時はD::pq_distanceの結果を優先度として優先度付きキューにノードを追加します． 以下に実際にこの処理を行う箇所のコードを示します． . } else { T margin = D::margin(nd, v, _f); q.push(make_pair(D::pq_distance(d, margin, 1), static_cast&lt;S&gt;(nd-&gt;children[1]))); q.push(make_pair(D::pq_distance(d, margin, 0), static_cast&lt;S&gt;(nd-&gt;children[0]))); } . ここで，各変数と関数の詳細は以下の通りです． . D: ベクトル間のメトリック | D::margin: クエリvから際（上述の解説ページに倣います）までの符号付き距離を計算 | D::pq_distance: 探索するノードの優先度を計算 | d: 根ノードから現在のノードに至るまでの最悪の優先度 | q: 探索するノードを決定するための優先度付きキュー | nd: 現在のノード | . 従って，ここではD::pq_distance(d, margin, 1)という優先度でnd-&gt;children[1]を，D::pq_distance(d, margin, 0)という優先度でnd-&gt;children[0]を，優先度キューに追加していることがわかります． . 次に，DをEuclideanとしてD::pq_distanceの詳細を示します．Euclideanにはpq_distanceが実装されていないため，実際にはMinkowskiの実装となります． . template&lt;typename T&gt; static inline T pq_distance(T distance, T margin, int child_nr) { if (child_nr == 0) margin = -margin; return std::min(distance, margin); } . 上記実装では，child_nr==0が成立する場合，marginの符号を反転しています． この処理の具体例を以下の図に示します． 子ノードとしてchildren[1]を選択した場合を考えます．この時，query1に対するマージンはmargin1，query2に対するマージンは-margin2となります． 同様に子ノードとしてchildren[0]を選択した場合を考えます．この時，query1に対するマージンは-marign1, query2に対するマージンはmargin2となります． . . その結果，子ノードの優先度は当該ノードが存在する側を正とした符号付き距離となります． . distanceは前述のd（現在のノードに至るまでの最悪の優先度）が割り当てられています． 従って，pq_distanceは優先度が悪化した場合にその値を更新する振る舞いとなっていることが解ります． . この性質によって，クエリが存在する側（優先度が正）のノードの探索が完了すると，クエリが存在しない側（優先度が負）のノードの探索に取り掛かります． この様に, 場合分け等を行うことなく適切に次に探索すべきノードを選択できている点が非常に面白い実装だと思いました． . 実装詳細 . 今回実装した主要なインターフェースと実装の関係を以下に示します． . . 上図の各要素の詳細は詳細は以下のとおりです． . Index: 類似ベクトル検索のインターフェース．このインターフェースを用いてデータの登録や検索を実施 | Candidate: 検索結果を表現する構造体 | flatIndex: 線形探索による類似ベクトル検索の実装 | bspTreeIndex: バイナリ空間分割木による類似ベクトル検索の実装 | CutPlane: 際のインターフェース．このインターフェースを用いて空間を分割 | kdCutPlane: Kd-Treeを実現するための際の実装 | rpCutPlane: Random Projection Treeを実現するための際の実装 | . Kd-TreeとRandom Projection Treeとは際をどの様に計算するかの違いしかありません． そこで，bspTreeIndexとCutPlaneの組み合わせで表現することとしました． 従って，Kd-Treeは . bspTreeIndex[T, U, kdCutPlane[T, U]] . と表現することができます．また，Random Projection Treeは . bspTreeIndex[T, U, rpCutPlane[T, U]] . と表現することができます． . ベンチマーク . 類似ベクトル検索のベンチマークにann-benchmarksがあります． 今回の実装をこのベンチマークに対応させることで，既存の実装とパフォーマンスを比較しました． . ann-benchmarksへアルゴリズムを追加する . ann-benchmarksへ新規にアルゴリズムを追加するためには，以下の作業が必要となります． また，これらの修正結果はこちらから取得可能です． . アルゴリズムが動作するイメージのDockerfileを追加 . ann-benchmarks/install/Dockefile.&lt;algorithm name&gt;というファイルに追加するアルゴリズムが動作するイメージの定義を記述します． ベンチマークを実施するための共通処理はann-benchmarksというイメージに実装されています． 従って，このイメージを継承して不足分を追記することになります． . 今回はGoでアルゴリズムを実装しました． 従って，以下のように . 実行ファイルをビルド | ベンチマーク用イメージにコピー | . という手順を踏むこととしました． . FROM golang:1.18-rc as builder RUN go install github.com/ar90n/countrymaam/cmd/countrymaam@latest FROM ann-benchmarks COPY --from=builder /go/bin/countrymaam /usr/local/bin . 類似ベクトル検索を行うプログラムを追加 . ann-benchmarks/ann_benchmarks/algorithms/&lt;algorithm name&gt;.pyというファイルに類似ベクトル検索を行うプログラムを記述します． 拡張子からも明らかですが，ベンチマークはPythonによって実装されています． 従って，類似ベクトル検索アルゴリズムもPythonから呼び出す必要があります． 具体的には，BaseANNを継承し以下のメソッドを実装します． . fit: インデックスを作成します．引数として，サイズが(サンプル数,次元)のnumpy.arrayが渡されます | set_query_arguments: テストセットに対する検索を行う前に一度だけ呼び出されます．検索に対するパラメータの設定を行います | query: 類似ベクトル検索を行います．引数としてクエリと求める類似ベクトルの数が渡されます | __init__: 引数として渡されたパラメータをもとにアルゴリズムの初期化します | __str__: 現在のパラメータとクラス名を文字列として返します | . 今回の実装ではPythonインターフェースを実装していません． 従って，実行ファイルをサブプロセスとして起動し，パイプを経由してデータの入出力を行います． 作成したクラスを以下に示します． . class Countrymaam(BaseANN): def __init__(self, metric, params): self._metric = metric self._index = params.get(&quot;index&quot;, &quot;kd-tree&quot;) self._n_trees = params.get(&quot;n_trees&quot;, 8) self._leaf_size = params.get(&quot;leaf_size&quot;, 8) def fit(self, X): X = X.astype(np.float64) suffix = &quot;&quot;.join(random.choices(string.ascii_lowercase, k=16)) index_file_path = f&quot;index_{suffix}_{os.getpid()}.bin&quot; # インデックスを作成し，ファイルに書き出す p = subprocess.Popen([ &quot;countrymaam&quot;, &quot;train&quot;, &quot;--dim&quot;, str(len(X[0])), &quot;--index&quot;, self._index, &quot;--leaf-size&quot;, str(self._leaf_size), &quot;--tree-num&quot;, str(self._n_trees), &quot;--output&quot;, index_file_path ], stdin=subprocess.PIPE) p.stdin.write(struct.pack(f&quot;={X.size}d&quot;, *np.ravel(X))) p.communicate() p.stdin.close() # インデックスを読み，クエリの入力を待機する self._pipe = subprocess.Popen([ &quot;countrymaam&quot;, &quot;predict&quot;, &quot;--dim&quot;, str(len(X[0])), &quot;--index&quot;, self._index, &quot;--input&quot;, index_file_path ], stdin=subprocess.PIPE, stdout=subprocess.PIPE) def set_query_arguments(self, search_k): self._search_k = search_k # 探索ノード数を設定 def query(self, v, n): v = v.astype(np.float64) self._pipe.stdin.write(struct.pack(f&quot;=i&quot;, self._search_k)) # 探索ノード数 self._pipe.stdin.write(struct.pack(f&quot;=i&quot;, n)) # 検索する類似ベクトル数 self._pipe.stdin.write(struct.pack(f&quot;={v.size}d&quot;, *v)) # クエリベクトル self._pipe.stdin.flush() rn = struct.unpack(&quot;=i&quot;, self._pipe.stdout.read(4))[0] ret = [0] * rn for i in range(rn): ret[i] = struct.unpack(&quot;=i&quot;, self._pipe.stdout.read(4))[0] return np.array(ret) def __str__(self): return f&quot;Countrymaam(index={self._index}, leaf_size={self._leaf_size} n_trees={self._n_trees}, search_k={self._search_k})&quot; . ベンチマークの設定ファイルにアルゴリズムの設定を追加 . ベンチマークに関する設定はann-benchmarks/algos.yamlというファイルに追記します． このファイルはデータ型 -&gt; メトリック -&gt; アルゴリズム という階層構造になっています． 従って，各アルゴリズムがサポートしているデータ型とメトリックに応じて，適切な位置に設定を記述する必要があります． . データ型とメトリックの組み合わせは以下の通りです． . float any | euclidean | angular | . | bit hamming | jaccard | . | . 今回実装したアルゴリズムはユークリッド距離にのみ対応しているためeuclideanに追記します． . アルゴリズムの階層に記述するパラメータは以下の通りです． . docker-tag: 使用するDockerイメージのタグ | module: アルゴリズムが実装されているモジュール | constructor: アルゴリズムの実装クラス | base-args: 全計測に渡ってconstructorに渡される引数の共通部分 | run-groups: constructorとset_query_arguments渡される引数の可変部分 | . 最終的な差分は以下の様になりました． . diff --git a/algos.yaml b/algos.yaml index 7c1ebe6..f170633 100644 a/algos.yaml +++ b/algos.yaml @@ -391,6 +391,28 @@ float: query-args: [[0.6, 0.8, 0.9, 1.0, 1.02, 1.05, 1.1, 1.2]] euclidean: + countrymaam-kd: + docker-tag: ann-benchmarks-countrymaam + module: ann_benchmarks.algorithms.countrymaam + constructor: Countrymaam + base-args: [&quot;@metric&quot;] + run-groups: + kd: + arg-groups: + - {&quot;index&quot;: [&quot;rkd-tree&quot;], &quot;n_trees&quot;: [8, 16, 32, 64], + &quot;leaf_size&quot;:[8, 16, 32, 64]} + query-args: [[16, 32, 64, 128, 256, 512, 1024, 2048]] + countrymaam-rp: + docker-tag: ann-benchmarks-countrymaam + module: ann_benchmarks.algorithms.countrymaam + constructor: Countrymaam + base-args: [&quot;@metric&quot;] + run-groups: + rp: + arg-groups: + - {&quot;index&quot;: [&quot;rrp-tree&quot;], &quot;n_trees&quot;: [8, 16, 32, 64], + &quot;leaf_size&quot;:[8, 16, 32, 64]} + query-args: [[16, 32, 64, 128, 256, 512, 1024, 2048]] vamana(diskann): docker-tag: ann-benchmarks-diskann module: ann_benchmarks.algorithms.diskann . run-groupsにおけるarg-groupsが__init__に渡されるパラメータを，query-argsがset_query_argumentsに渡されるパラメータを表します． arg-groupsの様に複数の属性からなるパラメータは各属性の直積が渡されます． . ベンチマークの実行 . ベンチマークは以下のコマンドで実行します．install.pyはコンテナの作成を，run.pyはベンチマークを実行します． &lt;algorithm name&gt;と&lt;dataset name&gt;は省略可能です．省略した場合，適用可能な全てのアルゴリズムまたはデータセットに対して処理を適用します． . $ python install.py --algorithm &lt;algorithm name&gt; $ python run.py --algorithm &lt;algorithm name&gt; --dataset &lt;dataset name&gt; . 結果 . 以下の結果は，fashion-mnist(Xiao et al., 2017)に対するベンチマークです．図中のflannとannoyはann-benchmarksのデフォルト設定を用いています． . . CPU: AMD Ryzen 9 3950X | Memory: 64GB | . 参考 . Xiao, H., Rasul, K., &amp; Vollgraf, R. (2017). Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms. | ann-benchmarks | Annoy | .",
            "url": "https://lab.ar90n.net/go/algorithm/machinelearning/vectorsimilaritysearch/2022/02/01/mimic-annoy-wiht-go.html",
            "relUrl": "/go/algorithm/machinelearning/vectorsimilaritysearch/2022/02/01/mimic-annoy-wiht-go.html",
            "date": " • Feb 1, 2022"
        }
        
    
  
    
        ,"post2": {
            "title": "cargo-editが上手く動かない時の回避策",
            "content": "はじめに . cargo-edit v0.8.0が上手く動かなかったので，その対処法についてのメモです． . やったこと . ssh-agentに秘密鍵を登録 | v0.7.0にダウングレード | . error authenticating: no auth sock variable; class=Ssh (23) でcargo-editをインストールすることができない . 単純に cargo install cargo-edit をすると，以下の様にssh-agentとの連携に失敗してエラーとなりました． . $ cargo install cargo-edit Updating crates.io index error: failed to fetch `https://github.com/rust-lang/crates.io-index` Caused by: failed to authenticate when downloading repository: ssh://git@github.com/rust-lang/crates.io-index * attempted ssh-agent authentication, but no usernames succeeded: `git` if the git CLI succeeds then `net.git-fetch-with-cli` may help here https://doc.rust-lang.org/cargo/reference/config.html#netgit-fetch-with-cli Caused by: error authenticating: no auth sock variable; class=Ssh (23) . 対処法はエラーメッセージの中に書いてあるので，以下の様にssh-agentの起動と秘密鍵の登録を行います． . $ eval `ssh-agent -s` Agent pid 1756 $ ssh-add Identity added: &lt;path to home&gt;/.ssh/id_rsa (&lt;mail address&gt;) . 再度，cargo install cargo-edit を実行すると無事にインストールできました． . $ cargo install cargo-edit Updating crates.io index Downloaded cargo-edit v0.8.0 Downloaded 1 crate (61.1 KB) in 0.40s Installing cargo-edit v0.8.0 ... Compiling crates-index v0.17.0 Compiling cargo-edit v0.8.0 Finished release [optimized] target(s) in 1m 05s Installing /usr/local/cargo/bin/cargo-add Installing /usr/local/cargo/bin/cargo-rm Installing /usr/local/cargo/bin/cargo-set-version Installing /usr/local/cargo/bin/cargo-upgrade Installed package `cargo-edit v0.8.0` (executables `cargo-add`, `cargo-rm`, `cargo-set-version`, `cargo-upgrade`) . Command failed due to unhandled error: authentication required but no callback set; class=Ssh (23); code=Auth (-16) で cargo add できない . cargo add でクレートを追加しようとすると，以下の様にエラーが発生します． . $ cargo add anyhow Updating &#39;https://github.com/rust-lang/crates.io-index&#39; index Command failed due to unhandled error: authentication required but no callback set; class=Ssh (23); code=Auth (-16) . こちらやこちらなど，同様のエラーに関する報告はちらほら上がっているようです．しかしながら，それらの回避策は私の環境では有効性を発揮しませんでした． 従って，cargo-edit のバージョンを v0.7.0 にダウンロードすることとしました． . $ cargo install --version 0.7.0 cargo-edit Downloaded cargo-edit v0.7.0 Downloaded 1 crate (57.6 KB) in 0.69s Updating crates.io index Installing cargo-edit v0.7.0 ... Replacing /usr/local/cargo/bin/cargo-upgrade Removing executable `/usr/local/cargo/bin/cargo-set-version` from previous version cargo-edit v0.8.0 Replaced package `cargo-edit v0.8.0` with `cargo-edit v0.7.0` (executables `cargo-add`, `cargo-rm`, `cargo-upgrade`) . この結果，以下の様に cargo add が動作する様になりました． . $ cargo add anyhow Updating &#39;https://github.com/rust-lng/crates.io-index&#39; index Adding anyhow v1.0.53 to dependenciesa . 参考 . cargo add no longer works with Git using SSH in 0.8.0 #515 | SSH support #333 | .",
            "url": "https://lab.ar90n.net/rust/2022/01/30/cargo-edit-workaround.html",
            "relUrl": "/rust/2022/01/30/cargo-edit-workaround.html",
            "date": " • Jan 30, 2022"
        }
        
    
  
    
        ,"post3": {
            "title": "AWS Amplifyのメモ",
            "content": "はじめに . AWS Amplifyを使ってみて個人的にハマったことのメモです． . やったこと . コンテナ（Fargate）に対して，環境に応じた環境変数を設定する | ロールに対して任意のポリシーを追加する | コンテナが配置されたVPCにリソースを配置する | . コンテナ（Fargate）に対して，環境に応じた環境変数を設定する . AWS AmplifyではAPIを実装するリソースとしてコンテナ（Fargate）がサポートされています．ですが，現状ではデプロイ環境（devやprodなど）に応じた環境変数を設定することができないようです．（少なくとも，私には見つけることができませんでした） . 最初は，CloudFormationの定義ファイルを手動で書き換えることで実現できると考えていました．ですが，実際に作業を進めるとこのファイルはamplify pushのたびにdocker-compose.yamlから生成されることが判明しました．そこで， . dev環境向けにdocker-compose.yaml.devを，prod環境向けにdocker-compose.yaml.prodをそれぞれ作成 | コマンドフックを利用して，amplify pushのタイミングでdocker-compose.yaml.devまたはdocker-compose.yaml.prodをdocker-compose.yamlにコピー | . という対応を採用しました． . ロールに対して任意のポリシーを追加する . カスタムリソースを追加した場合など，Lambdaに任意のポリシーを追加したい場合があると思います．そのような場合は，custom-policies.jsonを利用するのが楽です． 一応，ここやここなど，AWSの公式ドキュメントにも記載されているようですが，目立つところには記載されていないため気がつくまでに時間がかかりました． . コンテナが配置されたVPCにリソースを配置する . コンテナの配置されるVPCは, amplify/backend/backend-config.json中に記述されているNetworkStackというリソースによって作成されれます．NetworkStackは . CloudMapNamespaceId | ClusterName | Igw | SubnetIds | VpcCidrBlock | VpcId | VpcLinkId | . を出力します．必要なパラメータはリソースによって異なると思いますが，SubnetIdsやVpcIdなどを参照することでコンテナと同じVPC内にリソースを配置することができると思います． . 上記パラメータを参照するためには， . amplify/backend/backend-config.jsonにおいて，上記パラメータを参照するリソースのdependsOnにNetworkStackを追加 ... &quot;dependsOn&quot;: [ { &quot;category&quot;: &quot;&quot;, &quot;resourceName&quot;: &quot;NetworkStack&quot;, &quot;attributes&quot;: [ &quot;VpcId&quot;, &quot;SubnetIds&quot; ] } ] ... . | 上述のリソースのCloudFormationの設定ファイルにパラメータの設定を追加.この際，パラメータ名はNetworkStack&lt;Attribute名&gt;となります ... &quot;Parameters&quot;: { ... &quot;NetworkStackVpcId&quot;: { &quot;Type&quot;: &quot;String&quot; }, &quot;NetworkStackSubnetIds&quot;: { &quot;Type&quot;: &quot;CommaDelimitedList&quot; }, ... }, ... . | amplify env checkout &lt;env&gt;を実行して環境のチェックアウトを行う | 参考 . AWS CDKまたはCloudFormationを使用し、カスタムAWSリソースでAmplifyバックエンドを拡張する新機能「カスタム」のご紹介 | Amplify Docs | .",
            "url": "https://lab.ar90n.net/aws/web/cloud/amplify/2022/01/03/aws-amplify-tips.html",
            "relUrl": "/aws/web/cloud/amplify/2022/01/03/aws-amplify-tips.html",
            "date": " • Jan 3, 2022"
        }
        
    
  
    
        ,"post4": {
            "title": "USB to TTLx4ケーブルの作成",
            "content": "はじめに . USBハブとUSBシリアルコンバータとを組み合わせることで，USB(1ch) to TTL(4ch) の変換ケーブルを作成しました． . やったこと . type-cコネクタ，USBハブコントローラ基板，USBシリアルコンバータを組み合わせてUSB(1ch) to TTL(4ch)変換ケーブルを作成 | . 回路設計 . 特別なことは特に何もしていません．CH330のデータシートに従って単純に部品を繋いで行きました．type-cコネクタはVCC端子より5vを取得するため， ccを5.1kΩでプルダウンしています． . 今回，EasyEDAを使って回路図を起こしてみたのですが中々使い勝手がよかったです．ブラウザ内で全てが完結するので環境構築が非常に簡単です．私は使用しませんでしたがPCBエディタとの連携機能もあるようです．また，各種ボード(USB1とHUB1)とケーブル(TTL1からTTL4)のピン番号はシステムの都合上割り当てています．そのため，実際にはピン番号はありません．何か良い方法があると良いのですが． . . 実装 . 可能な限りケーブルの様に使いたかったので，USBハブコントローラ背面にカプトンテープを貼り，その上にUSBシリアルコンバータを実装しました． . . 次にケーブルを取り付け全体をグルーガンで固定します． . . 最後に熱収縮ケーブルで全体をさらに固定して完成です． . . 動作確認 . lsusbコマンドを実行すると以下のデバイスを確認できました．意図した通りに動作しているようです． . Bus 020 Device 018: ID 1a40:0101 TERMINUS TECHNOLOGY INC. USB 2.0 Hub Bus 020 Device 021: ID 1a86:7523 1a86 USB2.0-Serial Bus 020 Device 029: ID 1a86:7523 1a86 USB2.0-Serial Bus 020 Device 024: ID 1a86:7523 1a86 USB2.0-Serial Bus 020 Device 010: ID 1a86:7523 1a86 USB2.0-Serial . 後から気が付いたこと . 今回はUSBハブとUSBシリアルコンバータとを組み合わせて所望の機能を実現しました．しかしながら，調べてみると同様の機能をワンチップで実現するICがあるようです．次に同様のものを作る時はこちらを使いたいですね． . 参考 . USB 转串口芯片 CH330 | 組込み技術ラボ | .",
            "url": "https://lab.ar90n.net/hardware/2021/08/26/make-usb-to-ttlx4.html",
            "relUrl": "/hardware/2021/08/26/make-usb-to-ttlx4.html",
            "date": " • Aug 26, 2021"
        }
        
    
  
    
        ,"post5": {
            "title": "k3sクラスタ on Raspberry Pi 4",
            "content": "はじめに . Raspberry Pi 4+k3sで構築したクラスタに関するメモです． . やったこと . PC(master) + Raspberry Pi 4(worker)という構成でk3sクラスタを構築 | grafana + ptometheus + loki + node-exporter + promtailという構成で監視基盤を構築 | . Role関連の設定 . クラスタの監視を行うためには適切にサービスディスカバリを行う必要があります．そこで，サービスディスカバリに必要な権限を持つClusterRoleと対応するServiceAccountを定義します． /metricsにアクセスするためにはRoleではなくClusterRoleである必要があるようです．(monitoringネームスペース外にアクセスするから？) . apiVersion: v1 kind: Namespace metadata: name: monitoring apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRole metadata: name: monitoring rules: - apiGroups: [&quot;&quot;] resources: - nodes - nodes/proxy - services - endpoints - pods verbs: [&quot;get&quot;, &quot;list&quot;, &quot;watch&quot;] - apiGroups: - extensions resources: - ingresses verbs: [&quot;get&quot;, &quot;list&quot;, &quot;watch&quot;] - nonResourceURLs: [&quot;/metrics&quot;] verbs: [&quot;get&quot;] apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRoleBinding metadata: name: monitoring roleRef: kind: ClusterRole name: monitoring apiGroup: rbac.authorization.k8s.io subjects: - kind: ServiceAccount name: monitoring namespace: monitoring apiVersion: v1 kind: ServiceAccount metadata: name: monitoring namespace: monitoring . promtailの導入　 . とりあえず，ホストのログ(/var/log/*log)をmasterで稼働しているlokiに送信します．各podのログ収集については中途半端な設定となっています．（多分動かない） 各ログにはhostnameタグにホスト名を設定しています．これは，spec.nodeNameを環境変数NODE_NAMEに設定し，起動引数に--client.external-labels=hostname=$(NODE_NAME)を追加することで実現しています． . lokiはk3sクラスタ内ではなく，master上のDockerコンテナとしてホストされています．また，promtailはworkerとmaster両ノードにデプロイされます． そのため，両環境下からk3s-masterの名前解決を行うため，dnsPolicyをNoneとして明示的にdnsサーバーを設定しています． これは，ClusterFirstではクラスタ外にあるk3s-masterの名前解決を行うことができず，Defaultではworkerとmasterとで共通の舐め解決設定を作り出すことができなかったためです． . apiVersion: v1 kind: ConfigMap metadata: name: promtail-config namespace: monitoring data: config.yaml: | server: http_listen_port: 9080 grpc_listen_port: 0 positions: filename: /tmp/positions.yaml clients: - url: http://k3s-master:3100/loki/api/v1/push scrape_configs: - job_name: system static_configs: - targets: - localhost labels: job: varlogs __path__: /var/log/*log - job_name: kubernetes-pods-app kubernetes_sd_configs: - role: pod apiVersion: apps/v1 kind: DaemonSet metadata: name: promtail namespace: monitoring spec: selector: matchLabels: app: promtail template: metadata: labels: app: promtail spec: dnsPolicy: None dnsConfig: nameservers: - 10.0.100.1 serviceAccountName: monitoring containers: - name: promtail image: grafana/promtail:latest env: - name: TZ value: Asia/Tokyo - name: NODE_NAME valueFrom: fieldRef: fieldPath: spec.nodeName args: - --config.file=/etc/promtail/config.yaml - --client.external-labels=hostname=$(NODE_NAME) ports: - name: webui containerPort: 9080 volumeMounts: - name: config-volume mountPath: /etc/promtail - name: varlog mountPath: /var/log - name: secret-volume mountPath: /var/run/secrets - name: run mountPath: /run/promtail volumes: - name: config-volume configMap: name: promtail-config - name: varlog hostPath: path: /var/log - name: secret-volume hostPath: path: /var/run/secrets - name: run hostPath: path: /run/promtail . node-exporterの導入 . node-exporterもworkerとmaster両環境にデプロイされます． . apiVersion: apps/v1 kind: DaemonSet metadata: name: node-exporter namespace: monitoring spec: selector: matchLabels: app: node-exporter template: metadata: labels: app: node-exporter annotations: prometheus.io/scrape: &#39;true&#39; prometheus.io/port: &#39;9100&#39; prometheus.io/path: /metrics spec: dnsPolicy: Default serviceAccountName: monitoring containers: - name: node-exporter image: prom/node-exporter:latest env: - name: TZ value: Asia/Tokyo - name: NODE_NAME valueFrom: fieldRef: fieldPath: spec.nodeName args: - --path.procfs=/host/proc - --path.sysfs=/host/sys - --collector.filesystem.ignored-mount-points - ^/(sys|proc|dev|host|etc|rootfs/var/lib/docker/containers|rootfs/var/lib/docker/overlay2|rootfs/run/docker/netns|rootfs/var/lib/docker/aufs)($$|/) ports: - containerPort: 9100 name: http volumeMounts: - name: proc mountPath: /host/proc - name: sys mountPath: /host/sys - name: rootfs mountPath: /rootfs volumes: - name: proc hostPath: path: /proc - name: sys hostPath: path: /sys - name: rootfs hostPath: path: /rootfs . loki，prometheus，grafanaの導入 . これらのソフトウェアはDockerコンテナとしてホストされています．docker-compose.ymlは以下の通りです． . version: &quot;3.2&quot; networks: monitoring: services: loki: image: grafana/loki:latest ports: - &quot;3100:3100&quot; command: -config.file=/etc/loki/local-config.yaml volumes: - type: bind source: ./loki/local-config.yml target: /etc/loki/local-config.yaml networks: - monitoring restart: always grafana: image: grafana/grafana:latest ports: - &quot;3000:3000&quot; volumes: - type: bind source: ./grafana/provisioning target: /etc/grafana/provisioning - type: volume source: grafana_data target: /var/lib/grafana networks: - monitoring restart: always volumes: grafana_data: . local-config.yamlは以下の通りです．デフォルトから特に変更していなかったと思います． . auth_enabled: false server: http_listen_port: 3100 ingester: lifecycler: address: 127.0.0.1 ring: kvstore: store: inmemory replication_factor: 1 final_sleep: 0s chunk_idle_period: 1h # Any chunk not receiving new logs in this time will be flushed max_chunk_age: 1h # All chunks will be flushed when they hit this age, default is 1h chunk_target_size: 1048576 # Loki will attempt to build chunks up to 1.5MB, flushing first if chunk_idle_period or max_chunk_age is reached first chunk_retain_period: 30s # Must be greater than index read cache TTL if using an index cache (Default index read cache TTL is 5m) max_transfer_retries: 0 # Chunk transfers disabled schema_config: configs: - from: 2020-10-24 store: boltdb-shipper object_store: filesystem schema: v11 index: prefix: index_ period: 24h storage_config: boltdb_shipper: active_index_directory: /loki/boltdb-shipper-active cache_location: /loki/boltdb-shipper-cache cache_ttl: 24h # Can be increased for faster performance over longer query periods, uses more disk space shared_store: filesystem filesystem: directory: /loki/chunks compactor: working_directory: /loki/boltdb-shipper-compactor shared_store: filesystem limits_config: reject_old_samples: true reject_old_samples_max_age: 168h chunk_store_config: max_look_back_period: 0s table_manager: retention_deletes_enabled: false retention_period: 0s ruler: storage: type: local local: directory: /loki/rules rule_path: /loki/rules-temp alertmanager_url: http://localhost:9093 ring: kvstore: store: inmemory enable_api: true . 参考 . Lokiとpromtailことはじめ | Kubernetesの全NodeをPrometheusで監視する方法 | .",
            "url": "https://lab.ar90n.net/kubernetes/2021/08/21/k3s-cluster-on-rp4.html",
            "relUrl": "/kubernetes/2021/08/21/k3s-cluster-on-rp4.html",
            "date": " • Aug 21, 2021"
        }
        
    
  
    
        ,"post6": {
            "title": "Ubuntu 20.04をシリアルコンソール経由で操作する",
            "content": "はじめに . 普段SSHで管理しているサーバーが，ネットワーク関連のトラブルに見舞われると，いつも通りにログインできず色々と大変です． そこで，Ubuntu 20.04をシリアルコンソール経由で操作する環境を構築します． . やったこと . USB-TTLケーブルによる代用シリアルケーブルの作成 | udevによるケーブル挿入をトリガーとしたシリアルコンソールの有効化 | . ケーブル作成 . 特殊なケースを除くと，最近のPCにはシリアルポートが付属していません． そこで，２本のUSB-TTL変換ケーブルを直結することでシリアルケーブルの代用とします． 今回，安価に購入可能なこちらのケーブルを使用しました． 代用ケーブルの作成は，両ケーブルのピンソケットを切断し，以下の様に緑と白を交差して結線します． . &lt;赤&gt; - &lt;赤&gt; &lt;緑&gt; - /- &lt;緑&gt; &lt;白&gt; -/ - &lt;白&gt; &lt;黒&gt; - &lt;黒&gt; . 作成したケーブルの動作確認は両端をUSBポートに挿入し，接続したマシンで以下の様にcuコマンドを実行します． 接続が適切に行われると，一方の端末で入力した文字列が他方の端末に表示されると思います． （同一マシンでも可能です） . $ sudo cu -l /dev/ttyUSB0 # &lt;- ttyUSB0の部分は環境によります . シリアルコンソールの有効化 . 代用ケーブルを接続したマシンにて，以下のコマンド実行するとシリアルコンソールを有効化することができます． . $ sudo systemctl enable serial-getty@ttyUSB0.service # &lt;- ttyUSB0の部分は環境によります $ sudo systemctl start serial-getty@ttyUSB0.service # &lt;- ttyUSB0の部分は環境によります . その後，もう一方を接続したマシンにて，cuコマンドを用いて接続します．すると，以下の様にログインプロンプトが確認できます．(slimeはホスト名です) . $ sudo cu -l /dev/ttyUSB0 # &lt;- ttyUSB0の部分は環境によります Password: Connected. slime login: . udevによるシリアルコンソールの自動起動 . 常時ケーブルを刺しっぱなしにするのは不便なので，ケーブルを挿入したタイミングで，シリアルコンソールが有効化されるように設定します． ですが，普通にUSB-TTL変換ケーブルを使いたい時もあるので，単純にttyUSB0を関しするだけでは都合が悪そうです． そこで，特定のVendor IDとProduct IDを持つUSB-Serialデバイスが接続された場合のみシリアルコンソールを有効化します． Vendor IDとProduct IDは以下のコマンドで確認します． . $ udevadm test-builtin usb_id /sys/class/tty/ttyUSB0 Load module index Parsed configuration file /usr/lib/systemd/network/99-default.link Parsed configuration file /usr/lib/systemd/network/73-usb-net-by-mac.link Created link configuration context. ID_VENDOR=Prolific_Technology_Inc. ID_VENDOR_ENC=Prolific x20Technology x20Inc. ID_VENDOR_ID=067b ID_MODEL=USB-Serial_Controller ID_MODEL_ENC=USB-Serial x20Controller ID_MODEL_ID=2303 ID_REVISION=0300 ID_SERIAL=Prolific_Technology_Inc._USB-Serial_Controller ID_TYPE=generic ID_BUS=usb ID_USB_INTERFACES=:ff0000: ID_USB_INTERFACE_NUM=00 ID_USB_DRIVER=pl2303 Unload module index Unloaded link configuration context. . ID_VENDOR_ID=067b および ID_MODEL_ID=2303 とあるので，Vendor IDが067bかつProduct IDが2303であることが確認できます． これは，今回使用するケーブルはPL2303を使っているためです.従って，PL2303が接続されるとシリアルコンソールが有効化されることになります． . 以上の結果を元に，以下の様にudevの設定を追加します． . $ cat /etc/udev/rules.d/65-serial-console.rules ACTION==&quot;remove&quot;, GOTO=&quot;serial_end&quot; SUBSYSTEM!=&quot;tty&quot;, GOTO=&quot;serial_end&quot; ENV{ID_VENDOR_ID}==&quot;067b&quot;, ENV{ID_MODEL_ID}==&quot;2303&quot;, ENV{SYSTEMD_WANTS}+=&quot;serial-getty@ttyUSB$env{.ID_PORT}.service&quot; LABEL=&quot;serial_end&quot; . 1,2行目は，USB-TTLケーブル挿入時以外は処理をスキップすることを表しています． 4行目はVendor IDが067bかつProduct IDが2303である場合，対応するttyUSBに対してserial-gettyサービスを有効化することを表しています． . 設定後，以下のコマンドでケーブル挿入の前後でserial-getty@ttyUSB0.serviceが有効化されていることを確認できます． . ケーブル挿入前 | . $sudo systemctl status serial-getty@ttyUSB0.service ● serial-getty@ttyUSB0.service - Serial Getty on ttyUSB0 Loaded: loaded (/lib/systemd/system/serial-getty@.service; enabled; vendor preset: enabled) Active: inactive (dead) since Sun 2021-05-23 03:26:14 UTC; 2s ago Docs: man:agetty(8) man:systemd-getty-generator(8) http://0pointer.de/blog/projects/serial-console.html Process: 3803 ExecStart=/sbin/agetty -o -p -- u --keep-baud 115200,38400,9600 ttyUSB0 $TERM (code=killed, signal=HUP) Main PID: 3803 (code=killed, signal=HUP) May 23 03:26:14 slime systemd[1]: Stopped Serial Getty on ttyUSB0. . ケーブル挿入後 | . $ sudo systemctl status serial-getty@ttyUSB0.service ● serial-getty@ttyUSB0.service - Serial Getty on ttyUSB0 Loaded: loaded (/lib/systemd/system/serial-getty@.service; enabled; vendor preset: enabled) Active: active (running) since Sun 2021-05-23 03:26:21 UTC; 1s ago Docs: man:agetty(8) man:systemd-getty-generator(8) http://0pointer.de/blog/projects/serial-console.html Main PID: 4494 (agetty) Tasks: 1 (limit: 76982) Memory: 348.0K CGroup: /system.slice/system-serial x2dgetty.slice/serial-getty@ttyUSB0.service └─4494 /sbin/agetty -o -p -- u --keep-baud 115200,38400,9600 ttyUSB0 vt220 May 23 03:26:21 slime systemd[1]: Started Serial Getty on ttyUSB0. . 参考 . Ubuntu 15.10 でシリアルコンソールを有効にする | Ubuntu Weekly Recipe 第555回　いま，あらためてudev | Raspberry Pi 2 + systemd + udevで、USBデバイス挿入時にサービスを起動する | .",
            "url": "https://lab.ar90n.net/ubuntu/2021/05/26/use-serial-console-in-ubuntu.html",
            "relUrl": "/ubuntu/2021/05/26/use-serial-console-in-ubuntu.html",
            "date": " • May 26, 2021"
        }
        
    
  
    
        ,"post7": {
            "title": "Rustでレイトレーシングをしてみる",
            "content": "はじめに . Rustの勉強を兼ねて，こちらを参考にレイトレーシングを写経してみました． . メモ . 十分な数のRayを計算しなければ綺麗な画像は得られない．レイトレーシング結果のサンプルで，画素が黒く欠損しているのは十分な数のRayを計算していないから | Rayによってランダムにサンプリングすることで，ブラーやボケやアンチエイリアシングを表現する | 思っていたよりも単純 | . 結果 . 1週目 . | 2週目 . | . 参考 . Ray Tracing in One Weekend | Ray Tracing: the Next Week |",
            "url": "https://lab.ar90n.net/rust/computergraphics/2021/03/30/ray-tracing-in-weekend.html",
            "relUrl": "/rust/computergraphics/2021/03/30/ray-tracing-in-weekend.html",
            "date": " • Mar 30, 2021"
        }
        
    
  
    
        ,"post8": {
            "title": "glutinに入門してみる",
            "content": "はじめに . glutin に入門した記録です． Objファイルをロードして，スタンフォードバニーを表示するサンプルプログラムを作成します． . glutinとは . Rustで記述されたOpenGLのラッパーライブラリです． OpenGLのラッパーライブラリには抽象度が高いものから低いものまで様々あります． 本ライブラリは，それらの中でも抽象度が低い，低レベルな機能を提供することを目的としたライブラリです． したがって，OpenGL相当の非常にプリミティブな機能しか提供されていません． . glutinの実装の興味深い点に，ユーザが指定したAPIのバインディングをビルド時に動的に生成する点が挙げられます． この機能の利用方法については， サンプルプログラムの動作を通じて後述します． . サンプルプログラムの解析 . サンプルプログラムの実行 . リポジトリページにある手順に従ってサンプルプログラムを実行します． . $ git clone https://github.com/rust-windowing/glutin $ cd glutin $ cargo run --example window . すると，以下のようなウィンドウが表示されます． . . gl_bindings.rsの生成 . それでは，このサンプルプログラムの詳細をみていきます． . まず，Cargo.tomlを見てみます．すると，以下のようにbuild.rsがbuild scriptが設定されていることが確認できます． . [package] name = &quot;glutin_examples&quot; ... build = &quot;build.rs&quot; ... [build-dependencies] gl_generator = &quot;0.14&quot; . build.rsを確認すると，１２行目から１４行目において，GLES 2.0のバインディングを生成していることが確認できます． この処理は，gl_generatorを用いて実現されています． . use gl_generator::{Api, Fallbacks, Profile, Registry}; use std::env; use std::fs::File; use std::path::PathBuf; fn main() { let dest = PathBuf::from(&amp;env::var(&quot;OUT_DIR&quot;).unwrap()); println!(&quot;cargo:rerun-if-changed=build.rs&quot;); let mut file = File::create(&amp;dest.join(&quot;gl_bindings.rs&quot;)).unwrap(); Registry::new(Api::Gles2, (3, 3), Profile::Core, Fallbacks::All, []) .write_bindings(gl_generator::StructGenerator, &amp;mut file) .unwrap(); } . 次に，実際にどのようあファイルが生成されているかを確認します． 環境変数OUT_DIRはcargoによって設定されてしまうため，任意の値を設定することができません． そこで，以下のように環境変数名を変更します． . $ git diff diff --git a/glutin_examples/build.rs b/glutin_examples/build.rs index 77f6fa5..4ff7c4e 100644 a/glutin_examples/build.rs +++ b/glutin_examples/build.rs @@ -4,7 +4,7 @@ use std::fs::File; use std::path::PathBuf; fn main() { - let dest = PathBuf::from(&amp;env::var(&quot;OUT_DIR&quot;).unwrap()); + let dest = PathBuf::from(&amp;env::var(&quot;TMP_OUT_DIR&quot;).unwrap()); println!(&quot;cargo:rerun-if-changed=build.rs&quot;); . そして，ビルドするとgl_bindings.rsというファイルが作成されていることが確認できます． ファイルの内容を確認すると，GLES 2.0に利用されるデータ構造のバインディングか確認できます． . $ TMP_OUT_DIR=`pwd` cargo build --example window $ ls gl_bindings.rs gl_bindings.rs $ head -n 32 gl_bindings.rs mod __gl_imports { pub use std::mem; pub use std::marker::Send; pub use std::os::raw; } pub mod types { #![allow(non_camel_case_types, non_snake_case, dead_code, missing_copy_implementations)] // Common types from OpenGL 1.1 pub type GLenum = super::__gl_imports::raw::c_uint; pub type GLboolean = super::__gl_imports::raw::c_uchar; pub type GLbitfield = super::__gl_imports::raw::c_uint; pub type GLvoid = super::__gl_imports::raw::c_void; pub type GLbyte = super::__gl_imports::raw::c_char; pub type GLshort = super::__gl_imports::raw::c_short; pub type GLint = super::__gl_imports::raw::c_int; pub type GLclampx = super::__gl_imports::raw::c_int; pub type GLubyte = super::__gl_imports::raw::c_uchar; pub type GLushort = super::__gl_imports::raw::c_ushort; pub type GLuint = super::__gl_imports::raw::c_uint; pub type GLsizei = super::__gl_imports::raw::c_int; pub type GLfloat = super::__gl_imports::raw::c_float; pub type GLclampf = super::__gl_imports::raw::c_float; pub type GLdouble = super::__gl_imports::raw::c_double; pub type GLclampd = super::__gl_imports::raw::c_double; pub type GLeglImageOES = *const super::__gl_imports::raw::c_void; pub type GLchar = super::__gl_imports::raw::c_char; pub type GLcharARB = super::__gl_imports::raw::c_char; . 次に，ターゲットのAPIをApi::Glに変更して&#39;gl_bindings.rsを生成してみます. すると，先ほど生成したgl_bindings.rsとは内容が異なることが確認できます． このように，ターゲットや機能に合わせて，バックエンドを静的に切り替えて使用することが可能です． . $ mv gl_bindings.rs gl_bindings_gles2.rs $ git diff diff --git a/glutin_examples/build.rs b/glutin_examples/build.rs index 77f6fa5..7e149bd 100644 a/glutin_examples/build.rs +++ b/glutin_examples/build.rs @@ -4,12 +4,12 @@ use std::fs::File; use std::path::PathBuf; fn main() { - let dest = PathBuf::from(&amp;env::var(&quot;OUT_DIR&quot;).unwrap()); + let dest = PathBuf::from(&amp;env::var(&quot;TMP_OUT_DIR&quot;).unwrap()); println!(&quot;cargo:rerun-if-changed=build.rs&quot;); let mut file = File::create(&amp;dest.join(&quot;gl_bindings.rs&quot;)).unwrap(); - Registry::new(Api::Gles2, (3, 3), Profile::Core, Fallbacks::All, []) + Registry::new(Api::Gl, (3, 3), Profile::Core, Fallbacks::All, []) .write_bindings(gl_generator::StructGenerator, &amp;mut file) .unwrap(); } $ TMP_OUT_DIR=`pwd` cargo build --example window $ diff gl_bindings.rs gl_bindings_gles2.rs | head -n 32 121a122 &gt; #[allow(dead_code, non_upper_case_globals)] pub const ACTIVE_ATOMIC_COUNTER_BUFFERS: types::GLenum = 0x92D9; 123a125,126 &gt; #[allow(dead_code, non_upper_case_globals)] pub const ACTIVE_PROGRAM: types::GLenum = 0x8259; &gt; #[allow(dead_code, non_upper_case_globals)] pub const ACTIVE_RESOURCES: types::GLenum = 0x92F5; 128a132 &gt; #[allow(dead_code, non_upper_case_globals)] pub const ACTIVE_VARIABLES: types::GLenum = 0x9305; 129a134,136 &gt; #[allow(dead_code, non_upper_case_globals)] pub const ALIASED_POINT_SIZE_RANGE: types::GLenum = 0x846D; &gt; #[allow(dead_code, non_upper_case_globals)] pub const ALL_BARRIER_BITS: types::GLenum = 0xFFFFFFFF; &gt; #[allow(dead_code, non_upper_case_globals)] pub const ALL_SHADER_BITS: types::GLenum = 0xFFFFFFFF; 130a138 &gt; #[allow(dead_code, non_upper_case_globals)] pub const ALPHA_BITS: types::GLenum = 0x0D55; 133,135d140 &lt; #[allow(dead_code, non_upper_case_globals)] pub const AND: types::GLenum = 0x1501; &lt; #[allow(dead_code, non_upper_case_globals)] pub const AND_INVERTED: types::GLenum = 0x1504; &lt; #[allow(dead_code, non_upper_case_globals)] pub const AND_REVERSE: types::GLenum = 0x1502; 136a142 &gt; #[allow(dead_code, non_upper_case_globals)] pub const ANY_SAMPLES_PASSED_CONSERVATIVE: types::GLenum = 0x8D6A; 138a145,152 &gt; #[allow(dead_code, non_upper_case_globals)] pub const ARRAY_SIZE: types::GLenum = 0x92FB; &gt; #[allow(dead_code, non_upper_case_globals)] pub const ARRAY_STRIDE: types::GLenum = 0x92FE; &gt; #[allow(dead_code, non_upper_case_globals)] pub const ATOMIC_COUNTER_BARRIER_BIT: types::GLenum = 0x00001000; &gt; #[allow(dead_code, non_upper_case_globals)] pub const ATOMIC_COUNTER_BUFFER: types::GLenum = 0x92C0; &gt; #[allow(dead_code, non_upper_case_globals)] pub const ATOMIC_COUNTER_BUFFER_BINDING: types::GLenum = 0x92C1; &gt; #[allow(dead_code, non_upper_case_globals)] pub const ATOMIC_COUNTER_BUFFER_INDEX: types::GLenum = 0x9301; &gt; #[allow(dead_code, non_upper_case_globals)] pub const ATOMIC_COUNTER_BUFFER_SIZE: types::GLenum = 0x92C3; &gt; #[allow(dead_code, non_upper_case_globals)] pub const ATOMIC_COUNTER_BUFFER_START: types::GLenum = 0x92C2; 141,146d154 &lt; #[allow(dead_code, non_upper_case_globals)] pub const BACK_LEFT: types::GLenum = 0x0402; &lt; #[allow(dead_code, non_upper_case_globals)] pub const BACK_RIGHT: types::GLenum = 0x0403; &lt; #[allow(dead_code, non_upper_case_globals)] pub const BGR: types::GLenum = 0x80E0; . ウィンドウの表示とポリゴンの描画 . 先ほど実行したサンプルプログラムに対応するコードはこちらになります． それでは，こちらの内容を先頭から紹介していきます． . まずは，supportモジュールと利用するglutinのモジュールのインポートです． supportモジュールは，ポリゴンの生成と描画，頂点シェーダ，フラグメントシェーダなど，サンプルプログラムに表示された三角形を描画するための処理が含まれています． . mod support; use glutin::event::{Event, WindowEvent}; use glutin::event_loop::{ControlFlow, EventLoop}; use glutin::window::WindowBuilder; use glutin::ContextBuilder; . 次にmain関数です．main関数では，まず初めにイベントループ，ウィンドウ，このウインドウと紐づいたGLコンテキストを作成します． コード中のwindowed_contextとは，ウインドウとこのウィンドウに紐づいたGLコンテキストとを表現する構造体になります． . fn main() { let el = EventLoop::new(); let wb = WindowBuilder::new().with_title(&quot;A fantastic window!&quot;); let windowed_context = ContextBuilder::new().build_windowed(wb, &amp;el).unwrap(); let windowed_context = unsafe { windowed_context.make_current().unwrap() }; println!(&quot;Pixel format of the window&#39;s GL context: {:?}&quot;, windowed_context.get_pixel_format()); ... } . 次にコンテキストの取得を行います．この処理は，support::loadによって実現します． support::loadでは，以下のような処理が実行されます． . 頂点シェーダとフラグメントシェーダのコンパイル | シェーダプログラムの作成 | 三角形のポリゴンを表す頂点バッファオブジェクトと頂点配列オブジェクトの作成 | 上記各種リソースのGLコンテキストへの割り当て | . このコンテキストは上述のGLコンテキストを内部に持ち，各種描画処理を移譲します． . let gl = support::load(&amp;windowed_context.context()); . 最後にイベントハンドラです．このイベントハンドラは先ほど作成したイベントループ渡され，何かイベントが発生するたびに呼び出されます． 従って，イベントハンドラでは，発生したイベントの識別とそのイベントに対応する振る舞いを記述する必要があります． 各イベントに対する振る舞いについては，コード中にコメントとして追記しました． . el.run(move |event, _, control_flow| { println!(&quot;{:?}&quot;, event); *control_flow = ControlFlow::Wait; match event { Event::LoopDestroyed =&gt; return, // イベントループか破棄されたのでインベントハンドラから抜ける Event::WindowEvent { event, .. } =&gt; match event { WindowEvent::Resized(physical_size) =&gt; windowed_context.resize(physical_size), // ウインドウをリサイズ WindowEvent::CloseRequested =&gt; *control_flow = ControlFlow::Exit, // ウインドウを閉じる _ =&gt; (), }, Event::RedrawRequested(_) =&gt; { gl.draw_frame([1.0, 0.5, 0.7, 1.0]); // ポリゴンの描画． windowed_context.swap_buffers().unwrap(); // オフスクリーンに描画した結果を表示する } _ =&gt; (), } }); . スタンフォードバニーを表示する . Objファイルを読み取り，スタンフォードバニーを描画するサンプルプログラムを作成しました． このサンプルを実行すると，以下のような画面が表示されます． . . 全体の構成は，glutinのサンプルプログラムを大きく変更はありません， 従って，比較的容易に読み取ることが可能かと思います． しかしながら，幾つか新しい試みを行っているため，それらについて紹介します． . gl_bindings.rsのソースツリーへの取り込み . 前述した通り，gl_bindings.rsはビルド時に動的に生成されます．従って，これらが提供する型を編集時に取得することはできません． そのため，このままではコード補完や静的解析を行うことができません． Rustによる開発では，これらのツールは非常に重要であるため，このままでは非常に辛い開発が強いられます． . そこで，gl_buildings.rsをソースツリーに取り込んでしまうことにしました． 具体的には，以下のようにgl_bindings.rsの保存先を変更します． . fn main() { let mut dest = PathBuf::from(env!(&quot;CARGO_MANIFEST_DIR&quot;)); dest.push(&quot;src&quot;); println!(&quot;cargo:rerun-if-changed=build.rs&quot;); let mut file = File::create(&amp;dest.join(&quot;gl_bindings.rs&quot;)).unwrap(); Registry::new(Api::Gl, (3, 1), Profile::Core, Fallbacks::All, []) .write_bindings(gl_generator::StructGenerator, &amp;mut file) .unwrap(); } . この変更により，初回のビルド以降は以下のようにgl_bindings.rsがソースツリー内に存在します． 従って，コード補完や静的解析が適切に動作します． . $ ls ./src context.rs gl_bindings.rs main.rs obj.rs shader.rs . 注意点としては，gl_bindings.rsは動的に生成されるものなのでリポジトリに含んではいけないことです． 従って，以下のように.gitignoreに追加します． . $ cat .gitignore src/gl_bindings.rs target . Objファイルについて . Objファイルと呼ばれるファイルフォーマットには様々なものがあります． ここで使用するのは，3Dモデルを表現するために用いられるObjファイルです． また，Objファイルは頂点，面，法線など様々なデータを格納することができます． ここでは，以下のように頂点とそれらによって構成される面のみを対象とします． . v &lt;頂点番号1&gt; &lt;X座標1&gt; &lt;Y座標1&gt; &lt;Z座標1&gt; v &lt;頂点番号2&gt; &lt;X座標2&gt; &lt;Y座標2&gt; &lt;Z座標2&gt; ... f &lt;面番号1&gt; &lt;頂点番号i&gt; &lt;頂点番号j&gt; &lt;頂点番号k&gt; ... . 参考 . glutin |",
            "url": "https://lab.ar90n.net/rust/glutin/opengl/computergraphics/2021/02/01/getting-started-with-glutin.html",
            "relUrl": "/rust/glutin/opengl/computergraphics/2021/02/01/getting-started-with-glutin.html",
            "date": " • Feb 1, 2021"
        }
        
    
  
    
        ,"post9": {
            "title": "starshipの導入",
            "content": "Cicaを導入する . startshipを使用するためには，事前にNerdFontを導入する必要があります． そこで，今回はCicaを使用しました． 導入はリリースページから配布されているアーカイブをダウンロードしttfファイルをダブルクリックで完了です． . startshipを導入する . brewを使ってstartshipを導入します． . $ brew install starship . 以下のように良い感じです． . .",
            "url": "https://lab.ar90n.net/tool/2021/01/06/install-starship.html",
            "relUrl": "/tool/2021/01/06/install-starship.html",
            "date": " • Jan 6, 2021"
        }
        
    
  
    
        ,"post10": {
            "title": "Ubuntu 20.04 LTS Server でUSB-NICを使う",
            "content": "はじめに . このUSB-NICをUbuntu 20.04から使用するために行った作業記録です． . やったこと . ネットワークデバイスを有効 | netplanで静的IPアドレスを設定 | . 現状の確認 . USBポートに差し込んだのみでは，ネットワークデバイスとして使用可能な状態にはなりませんでした． まずは，USBデバイスとして適切に認識されていることを確認します． . $ lsusb Bus 002 Device 002: ID 0b95:1790 ASIX Electronics Corp. AX88179 Gigabit Ethernet Bus 002 Device 001: ID 1d6b:0003 Linux Foundation 3.0 root hub Bus 001 Device 002: ID 8087:0a2a Intel Corp. Bus 001 Device 001: ID 1d6b:0002 Linux Foundation 2.0 root hub . ASIX Electronics Corp. AX88179 Gigabit Ethernet このデバイスが対象のUSB-NICであるようです． . ネットワークデバイスとして認識する . 参考サイトの方法に従ってネットワークデバイスとして認識させます． . $ sudo lshw -c Network ... *-network:0 DISABLED description: Ethernet interface physical id: 1 bus info: usb@2:4 logical name: enx000ec6853d1a serial: 00:0e:c6:85:3d:1a size: 10Mbit/s capacity: 1Gbit/s capabilities: ethernet physical tp mii 10bt 10bt-fd 100bt 100bt-fd 1000bt 1000bt-fd autonegotiation configuration: autonegotiation=off broadcast=yes driver=ax88179_178a duplex=half link=no multicast=yes port=MII speed=10Mbit/s ... $ sudo ifconfig enx000ec6853d1a up $ ifconfig ... enx000ec6853d1a: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt; mtu 1500 inet6 fe80::20e:c6ff:fe85:3d1a prefixlen 64 scopeid 0x20&lt;link&gt; ether 00:0e:c6:85:3d:1a txqueuelen 1000 (イーサネット) RX packets 39 bytes 3635 (3.6 KB) RX errors 0 dropped 32 overruns 0 frame 0 TX packets 7 bytes 882 (882.0 B) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0 ... . /etc/cloud/cloud.cfg.d/50-curtin-networking.cfgにenx000ec6853d1aの設定を追加 . $ cat /etc/cloud/cloud.cfg.d/50-curtin-networking.cfg network: ethernets: enp2s0: addresses: [] dhcp4: true enx000ec6853d1a: addresses: - 10.0.100.1/24 gateway4: 10.0.0.1 dhcp4: false version: 2 $ sudo cloud-init clean -r . ここでシステムが再起動します．その後，以下の様に設定確認します． . $ ifconfig ... enx000ec6853d1a: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt; mtu 1500 inet 10.0.100.1 netmask 255.255.255.0 broadcast 10.0.100.255 inet6 fe80::20e:c6ff:fe85:3d1a prefixlen 64 scopeid 0x20&lt;link&gt; ether 00:0e:c6:85:3d:1a txqueuelen 1000 (イーサネット) RX packets 2163 bytes 212391 (212.3 KB) RX errors 0 dropped 1734 overruns 0 frame 0 TX packets 18 bytes 1900 (1.9 KB) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0 ... . 参考 . Ubuntu 16.04.5で有線LANが繋がらない | .",
            "url": "https://lab.ar90n.net/ubuntu/2020/10/17/usb-nic-in-ubuntu-server.html",
            "relUrl": "/ubuntu/2020/10/17/usb-nic-in-ubuntu-server.html",
            "date": " • Oct 17, 2020"
        }
        
    
  
    
        ,"post11": {
            "title": "DICOMにおける文字コードの取り扱い",
            "content": "はじめに . DICOMを取り扱うライブラリの多くは海外製であるため，日本語の取り扱いが得意で無いことが多いです. そこで，DICOMにおいて日本語を正しく扱うために色々と調べたのでまとめます． . やったこと . DICOMで日本語を表現する方法を調査 | . 文字コードについて復習 . DICOMにおける文字コードの取り扱いについて述べる前に，いわゆる”文字コード”と呼ばれているものは何であるかを簡単に復習します．より正しく”文字コード”について理解するためには，（符号化）文字集合と（文字）符号化方式を区別することが重要です．文字集合とは表現する文字の集合（アルファベット全てやひらがな全てなど）です．符号化方式とは文字集合の要素をコンピュータ上で取り扱うことが可能な形式に変換する方法です．従って，同一の文字集合に対して複数の符号化方式が存在します． . ISO/IEC 2022 とはなんだろう . ISO/IEC 2022とは文字集合を７ビット文字または８ビット文字にて表現する符号化方式です．特徴としてはエスケープシーケンスを利用することで，複数の文字集合を同時に取り扱うことが可能である点が挙げられます．日本語においては，このISO/IEC 2022の機構を利用したISO-2022-JPが広く利用されています．ISO-2022-JPは一般的にJISコードと呼ばれます．これには漢字，ひらがな，カタカナ，ラテン文字，ギリシア文字，キリル文字など多くの文字集合が含まれます．（半角カタカナは含まれません） . 上述した通り，ISO/IEC 2022には7ビット文字を利用したものと8ビット文字を利用したものとが存在します．ここでは８ビット文字を利用した場合のみを考慮します．ISO/IEC 2022の符号表は図形文字の領域（GL，GR）と制御文字の領域（CL，CR)からなります．また，４つの仮想的なバッファ(G0, G1, G2,G3)が存在します．ISO/IEC 2022を利用するには，エスケープシーケンスを用いて任意のバッファへ文字集合をロードし，それを図形文字の領域（GL，GR)に呼び出します．呼び出しには永続的に呼び出すロッキングシフトと１文字のみのシングルシフトが存在します． . DICOMにおけるISO/IEC 2022 . DICOMでは符号方式としてISO/IEC 2022のサブセットを用いています．具体的には . 8ビット文字をサポート | デフォルトの文字集合としてISO646を使用 | ISO646は必ずGL空間に呼び出される | ISO646以外の文字集合を用いる場合はSpecific Character Set(0008,0005)に指定する | エスケープを利用した符号拡張を使う(ISO/IEC 2022)場合はSpecific Character Setに二つ以上の文字集合を指定する | バッファG0はGLに，バッファG1はGRにロードされる | G2，G3は利用不可 | G0，G1は常に呼び出し状態にあるのでロッキングシフトは不要 | . という制約があります． . 実際にDICOMで日本語を扱ってみる . DICOMで日本語を扱うためには，Specific Character Set(0008,0005)に使用する符号方式を設定する必要があります．ここでは，以下の患者名を符号化することを考えます． . ﾔﾏﾀﾞ^ﾀﾛｳ=山田^太郎=やまだ^たろう . この患者名には，半角かな，漢字，全角ひらがなが含まれています．英数字と半角かなはISO 2022 IR 13で，漢字と全角ひらがなはISO 2022 IR 87で表現が可能です． 従って，Specific Character Set(0008,0005)には以下の値を設定します． . ISO 2022 IR 13 ISO 2022 IR 87 . 前述の通り，ISO/IEC 2022ではエスケープシーケンスを用いて複数の符号方式を切り替えます． 従って，上述の患者名においても適切なタイミングでエスケープする必要があります． エスケープシーケンスを追加した例を以下にしまします． . ﾔﾏﾀﾞ^ﾀﾛｳ= ESC 02/04 04/02 山田 ESC 02/08 04/10 ^ ESC 02/04 04/02 太郎 ESC 02/08 04/10 = ESC 02/04 04/02 やまだ ESC 02/08 04/10 ^ ESC 02/04 04/02 たろう ESC 02/08 04/10 . また，各エスケープシーケンスの詳細を以下に示します． . エスケープシーケンス 処理 . ESC 02/08 04/10 | 英数字(ISO-IR 14)をGLにロード | . ESC 02/04 04/02 | 漢字とひらがな(ISO-IR 87)をGLにロード | . これらを踏まえて，実際にエンコーディングすると以下の値が得られます． . 13/04 12/15 12/00 13/14 05/14 12/00 13/11 11/03 03/13 01/11 02/04 04/02 03/11 03/03 04/05 04/04 01/11 02/08 04/10 05/14 01/11 02/04 04/02 04/02 04/00 04/15 03/10 01/11 02/08 04/10 03/13 01/11 02/04 04/02 02/04 06/04 02/04 05/14 02/04 04/00 01/11 02/08 04/10 05/14 01/11 02/04 04/02 02/04 03/15 02/04 06/13 02/04 02/06 01/11 02/08 04/10 . 参考 . JIS漢字コード | ISO/IEC 2022 | JIS X 0201 | ２０１１ ST講座 入門講座 DICOM規格 初級 –DICOMをうまく使いこなす– | DICOMの日本語エンコーディング処理実装 | DICOM に慣れる － 現場で DICOM 接続に慌てないための知識 （２） 文字系の通信 － | H.3 Example of Person Name Value Representation in the Japanese Language | .",
            "url": "https://lab.ar90n.net/dicom/2020/10/12/character-encodings-in-dicom.html",
            "relUrl": "/dicom/2020/10/12/character-encodings-in-dicom.html",
            "date": " • Oct 12, 2020"
        }
        
    
  
    
        ,"post12": {
            "title": "GitHub ActionsでWebサイトを自動更新する",
            "content": "はじめに . GitHubPages + GitHub Actions でコンテンツを自動的に更新するWebサイトをつくってみました．GitHub Trending に登場したリポジトリに付与されていた topics を一覧表示するサイトです．言語ごとの用途がざっくりとした感じでみることができます． . Topics in GitHub Trending - GitHub . 今回，勉強も兼ねてフロントエンドとデータのクローリング処理共に Elm で記述しました． . GitHub Actions によるバッチ処理の定刻実行 . GitHub Actionsによって定刻実行されるバッチ処理はは以下の3つのジョブからなります． . build | crawl | push | . それぞれ，クローリングスクリプトのビルド，データのクローリング，データのリポジトリへのプッシュを行います．設定の詳細はこちらを参考にしてください． . CLIプログラムを Elm で書く . crawlジョブではElmで記述されたCLIプログラムを実行してデータの取得を行います．ElmはWebフロントエンドを記述することに特化している言語です．そのため，CLIプログラムの開発に必要な，コマンドライン引数の処理といった機能がサポートされいません．そこで，今回は以下のパッケージを持ちました． . pdillonkearns/elm-cli-options-parser . こちらのパッケージを用いると，Flagを用いてコマンドライン引数へのアクセスが可能となります．今回のプログラムでは，以下の様にgithubToken と language と dataRange とを引数から受け取っています． . init : Flags -&gt; TrendingApiOptions -&gt; ( Model, Cmd Msg ) init { githubToken } { language, dateRange } = ( { githubToken = githubToken } , attemptApi TrendingApiResponse (fetchTrending githubToken language dateRange) ) . また，GitHub Tredingsの取得は以下のAPIを利用させていただきました． . github-trending-api . クローリング結果の保存 . 今回，GitHub PagesのみでWebサイトをホスティングするため，データベースを使用することはできません．そのため，クローリング結果はJSONに整形されたのちに，直接GitHub Pagesのリポジトリにプッシュされます． . topics . この，JSONをフロントエンドから取得することで動的なコンテンツ更新を実現します． . Elmによるフロントエンド開発 . 特筆すべきことはありません．Elmは本当に書きやすい言語でした． . 所感 . Elmの勉強としてはちょうど良い分量でした．GitHub PagesとGitHub Actionsで結構なことができる印象なので，また何かチャレンジしたいですね． .",
            "url": "https://lab.ar90n.net/elm/web/2020/08/09/automated-update-github-pages.html",
            "relUrl": "/elm/web/2020/08/09/automated-update-github-pages.html",
            "date": " • Aug 9, 2020"
        }
        
    
  
    
        ,"post13": {
            "title": "純粋なバイナリヒープ",
            "content": "純粋なヒープを実装する場合，Braun Treeなど色々と適したデータ構造があるらしいですね． でも、あまり詳しくないので今回は馴染みの深いバイナリヒープを実装する方法について調べてみました． . バイナリヒープとは？ . 二分木を用いて実装したヒープです．ヒープとは以下の性質をもつデータ構造です． . 木構造をもつ | 常に子要素の値は親要素の値以上 | . ヒープ自身の詳細についてはこの記事を参考にしてください． . バイナリヒープを純粋に実装する . 一般的にバイナリヒープの実装には配列とそのインデックスを用いることが多いと思います．（上記のウィキペディアにもこの方法が記載されています） しかしがなら，この方法は配列の内容を書き換える必要があるため，純粋ではありません．そこで，今回は以下で提案されている手法を用いました． . A Functional Approach to Standard Binary Heaps . この論文では，純粋なバイナリヒープの挿入，構築，削除の各操作ついてScalaを用いて説明しています． 以降，これらについて簡単に紹介を行います． . ヒープクラス . この論文ではバイナリヒープを表現するためのクラスHeapを以下のように定義しています， . abstract sealed class Heap { def min: Int // ヒープの最小値 def left: Heap //左側の子要素 def right: Heap //右側の子要素 def size: Int //ヒープに含まれる要素数 def height: Int //ヒープの高さ } case class Branch(min: Int, left: Heap, right: Heap, size: Int, height: Int) extends Heap case object Leaf extends Heap { def min: Int = fail(&quot;Leaf.min&quot;) def left: Heap = fail(&quot;Leaf.min&quot;) def right: Heap = fail(&quot;Leaf.right&quot;) def size: Int = 0 def height: Int = 0 } . 上述の通り，Heapクラスのleftとrightを持つ再帰的な構造になっています． また，Heapクラスは抽象クラスであるため，一つ以上の子要素を持つBranchと子要素を持たないLeafとを派生させています． 単純な二分木にはsizeとheightは必須ではありません．しかしながら，今回のようにバイナリヒープを実現するためには非常に重要となってきます． . 挿入 O(log n) . 新たな要素をを挿入する際に気をつけなければいけないことは，要素を挿入したバイナリヒープもまた上述の条件を満たさなければならないということです． そこで，今回の実装では挿入処理を以下の二つの処理に分けて考えます． . 要素をLeafとして最下レベルに追加する． | 1.にて追加した要素を適切な位置まで上へ登らせる（bubbleUp）． | それでは，まずは1.の新たな要素をLeafとして追加する方法について解説します． ノード追加すること自体は言語側でやってくれることなので，基本的には問題になりません． そのため，次にLeafを挿入する場所はどこかを知ることが問題となります． . 二分木に対する操作のパフォーマンスは木の高さに依存するため，可能な限り二分木の高さを抑える必要があります． 従って，新たな要素はleft側から順番に挿入します． バイナリヒープは二分木であるため，ルートから適切にleftまたはrightを選択することで任意の位置に到達することが可能です． そのため，この問題はleftとrightを以下のように4つの場合に分けて考えることで解決することができます． . leftが完全二分木でない場合 -&gt; leftを選択 | leftが完全二分木であるが，rightは完全二分木でない場合 -&gt; rightを選択 | leftもrightも完全二分木であるが，leftの方がrightよりも高い場合 -&gt; rightを選択 | leftもrightも完全二分木であり，高さが等しい場合 -&gt; leftを選択 | これら4つの場合を図に表すと以下のようになります． . . また，Heapが完全二分木であるか否かは以下の条件式で求めることが可能です． . Size==2Height−1Size == 2^{Height} - 1Size==2Height−1 . 次に，2.のbubbleUpの方法について解説します． bubbleUpの処理は単純で，自身の値(min)と子要素の値(min)とを比較し，子要素の値(min)の値の方が小さい場合は要素を入れ替えます． 以上の結果を元に，insertとbubbleUpは以下のように実装することができます． . def bubbleUp(x: Int, l: Heap, r: Heap): Heap = (l, r) match { case (Branch(y, lt, rt, _, _), _) if (x &gt; y) =&gt; Heap(y, Heap(x, lt, rt), r) case (_, Branch(z, lt, rt, _, _)) if (x &gt; z) =&gt; Heap(z, l, Heap(x, lt, rt)) case (_, _) =&gt; Heap(x, l, r) } def insert(x: Int): Heap = if (isEmpty) Heap(x) else if (left.size &lt; math.pow(2, left.height) - 1) bubbleUp(min, left.insert(x), right) else if (right.size &lt; math.pow(2, right.height) - 1) bubbleUp(min, left, right.insert(x)) else if (right.height &lt; left.height) bubbleUp(min, left, right.insert(x)) else bubbleUp(min, left.insert(x), right) . 構築 O(n) . ソートされていない配列からバイナリヒープの構築を試みます． ここでは，構築済みのバイナリヒープをleftとrightに，配列のi番目の要素をminに設定した要素を考えます． しかしながら，配列のi番目の要素が各子要素の値(min)より小さいとは限らないため，全体としてヒープの条件を満たすとは限りません． そこで，ヒープの条件を満たさない場合は，配列のi番目の要素を適切な位置まで降ろす操作(bubbleDown)が必要となります． . bubbleDownはHeapのminの値と各子要素のminの値とを比較し，小さな場合は何もせず， 大きな場合は要素を入れ替えた後に，再帰的にbubbleDownを呼びだします． こうすることで，当該要素を適切な位置まで降ろすことができます． 以上の結果を踏まえ，配列からバイナリヒープを構築する関数heapify及びbubbleUpは以下のように定義できます． . def bubbleDown(x: Int, l: Heap, r: Heap): Heap = (l, r) match { case (Branch(y, _, _, _, _), Branch(z, lt, rt, _, _)) if (z &lt; y &amp;&amp; x &gt; z) =&gt; Heap(z, l, bubbleDown(x, lt, rt)) case (Branch(y, lt, rt, _, _), _) if (x &gt; y) =&gt; Heap(y, bubbleDown(x, lt, rt), r) case (_, _) =&gt; Heap(x, l, r) } def heapify(a: Array[Int]): Heap = { def loop(i: Int): Heap = if (i &lt; a.length) bubbleDown(a(i), loop(2 * i + 1), loop(2 * i + 2)) else Leaf loop(0) } . heapifyは一見するとを$O(n log n)$に見えますが，漸近的には$O(n)$らしいです． 正直，なぜ$O(n)$に成るのかは理解できていませんが，アルゴリズムイントロダクションに詳細が記載されているとあったので，そのうち調べてみようと思います． . 削除 O(log n) . 要素をの削除も挿入と同様， 以下のように二つのの処理に分けて考えることができます． . 最後に挿入した要素をバイナリヒープのルートへ移動させる | 1.でルートへ移動した要素を適切な位置まで降ろす(bubbleDown) | 最後に挿入した要素は挿入処理と同様に二分木を走査し，当該要素を見つけることで実現します． 要素を適切な位置まで降ろす処理(bubbleDown)は構築の際に用いたものと同一です． 以上の結果より，要素を削除する関数removeは以下のように実装されます． なお，floatLeftは左側の，floatRightは右側の子要素の値と親要素の値を交換する関数です. . def remove: Heap = if (isEmpty) fail(&quot;Empty heap.&quot;) else bubbleRootDown(mergeChildren(left, right)) def bubbleRootDown(h: Heap): Heap = if (h.isEmpty) Leaf else Heap.bubbleDown(h.min, h.left, h.right) def mergeChildren(l: Heap, r: Heap): Heap = if (l.isEmpty &amp;&amp; r.isEmpty) Leaf else if (l.size &lt; math.pow(2, l.height) - 1) floatLeft(l.min, mergeChildren(l.left, l.right), r) else if (r.size &lt; math.pow(2, r.height) - 1) floatRight(r.min, l, mergeChildren(r.left, r.right)) else if (r.height &lt; l.height) floatLeft(l.min, mergeChildren(l.left, l.right), r) else floatRight(r.min, l, mergeChildren(r.left, r.right)) def floatLeft(x: Int, l: Heap, r: Heap): Heap = l match { case Branch(y, lt, rt, _, _) =&gt; Heap(y, Heap(x, lt, rt), r) case _ =&gt; Heap(x, l, r) } def floatRight(x: Int, l: Heap, r: Heap): Heap = r match { case Branch(y, lt, rt, _, _) =&gt; Heap(y, l, Heap(x, lt, rt)) case _ =&gt; Heap(x, l, r) } . F#によるプライオリティキュー . バイナリヒープを使ったプライオリティキューの実装です． . PriorityQueue . 参考文献ではScalaによる実装でしたが，自分が普段使いする言語はF#なので，F#で実装してみました． .",
            "url": "https://lab.ar90n.net/algorithm/2020/06/27/purely-binary-heap.html",
            "relUrl": "/algorithm/2020/06/27/purely-binary-heap.html",
            "date": " • Jun 27, 2020"
        }
        
    
  
    
        ,"post14": {
            "title": "三次元空間における行列演算の復習",
            "content": "ぱっと思いつかなかったのでメモ． . 任意の単位ベクトルへの射影行列 . 任意の単位ベクトルを$ vec{n}$とすると，$ vec{n}$への射影行列$P_{p}$は以下の様に表されます． . Pp=n⃗n⃗TP_{p} = vec{n} vec{n}^{T}Pp​=n . n . T . 法線ベクトルに直交する平面への射影行列 . 法線ベクトルへの射影を元のベクトルから引くことで，法線ベクトルと直交する平面への射影が可能となります． そのため，法線ベクトルと直交する平面への射影行列$P_{o}$は以下のように表されます． . Po=I−Pp=I−n⃗n⃗T begin{aligned} P_{o} &amp;= I - P_{p} &amp;= I - vec{n} vec{n}^{T} end{aligned}Po​​=I−Pp​=I−n . n . T​ . 任意の単位ベクトルを回転軸とした回転行列 . 任意の単位ベクトル$ vec{n}$を以下のように定義します． n⃗=(nx,ny,nz) vec{n} = left(n_x, n_y, n_z right)n=(nx​,ny​,nz​) . ここで，Z軸方向の単位ベクトル$ vec{e_{z}}$を$ vec{n}$に変換する行列$P$を考えます．$P$はY軸回転$R_{y}$とZ軸回転$R_{z}$の積で以下のように表現できます． cθ=nxnx2+ny2sθ=nynx2+ny2cϕ=nznx2+ny2+nz2sϕ=nx2+ny2nx2+ny2+nz2Rxz=(cϕ0sϕ010−sϕ0cϕ)Rxy=(cθ−sθ0sθcθ0001)P=Rxy∗Rxz begin{aligned} c_{ theta} &amp;= frac{n_{x}}{ sqrt{n_{x}^{2} + n_{y}^{2}}} s_{ theta} &amp;= frac{n_{y}}{ sqrt{n_{x}^{2} + n_{y}^{2}}} c_{ phi} &amp;= frac{n_{z}}{ sqrt{n_{x}^{2} + n_{y}^{2} + n_{z}^{2}}} s_{ phi} &amp;= frac{ sqrt{n_{x}^{2} + n_{y}^{2}}}{ sqrt{n_{x}^{2} + n_{y}^{2} + n_{z}^{2}}} R_{xz} &amp;= left( begin{array}{rrr} c_{ phi} &amp; 0 &amp; s_{ phi} 0 &amp; 1 &amp; 0 -s_{ phi}&amp; 0 &amp; c_{ phi} end{array} right) R_{xy} &amp;= left( begin{array}{rrr} c_{ theta} &amp; -s_{ theta} &amp; 0 s_{ theta} &amp; c_{ theta} &amp; 0 0 &amp; 0 &amp; 1 end{array} right) P &amp;= R_{xy} * R_{xz} end{aligned}cθ​sθ​cϕ​sϕ​Rxz​Rxy​P​=nx2​+ny2​​nx​​=nx2​+ny2​​ny​​=nx2​+ny2​+nz2​​nz​​=nx2​+ny2​+nz2​​nx2​+ny2​​​=⎝⎜⎜⎜⎜⎜⎛​cϕ​0−sϕ​​010​sϕ​0cϕ​​⎠⎟⎟⎟⎟⎟⎞​=⎝⎜⎜⎜⎜⎜⎛​cθ​sθ​0​−sθ​cθ​0​001​⎠⎟⎟⎟⎟⎟⎞​=Rxy​∗Rxz​​ . $P$によって変換されたZ軸を$ vec{e_{z}’}(= vec{n})$とすると，所望の任意の単位ベクトルを回転軸とする回転行列は以下の３つの変換の合成で表すことができます． . $ vec{e_{z}}$を$ vec{e_{z}}’$に変換する$P$ | $ vec{e_{z}}$を回転軸とする回転$R_{a}$ | $ vec{e_{z}}’$を$ vec{e_{z}}$に変換する$P^{T}$ | したがって，最終的な回転行列$R$は以下のように表されます． . Ra=(cos⁡(a)−sin⁡(a)0sin⁡(a)cos⁡(a)0001)R=P∗Ra∗PT=(nx2+(ny2+nz2)cos⁡(a)−nxnycos⁡(a)+nxny−(nz3+(nx2+ny2)nz)sin⁡(a)−nxnzcos⁡(a)+nxnz+nysin⁡(a)−nxnycos⁡(a)+nxny+(nz3+(nx2+ny2)nz)sin⁡(a)ny2+(nx2+nz2)cos⁡(a)−nynzcos⁡(a)+nynz−nxsin⁡(a)−nxnzcos⁡(a)+nxnz−(nx2ny+ny3+nynz2)sin⁡(a)−nynzcos⁡(a)+nynz+(nx3+nxny2+nxnz2)sin⁡(a)nz2+(nx2+ny2)cos⁡(a))=(cos⁡(a)+nx2(1−cos⁡(a))nxny(1−cos⁡(a))−nzsin⁡(a)nxnz(1−cos⁡(a))+nysin⁡(a)nxny(1−cos⁡(a))+nzsin⁡(a)cos⁡(a)+ny2(1−cos⁡(a))nynz(1−cos⁡(a))−nxsin⁡(a)nxnz(1−cos⁡(a))−nysin⁡(a)nynz(1−cos⁡(a))+nxsin⁡(a)cos⁡(a)+nz2(1−cos⁡(a))) begin{aligned} R_{a} &amp;= left( begin{array}{rrr} cos left(a right) &amp; - sin left(a right) &amp; 0 sin left(a right) &amp; cos left(a right) &amp; 0 0 &amp; 0 &amp; 1 end{array} right) R &amp;= P * R_{a} * P^{T} &amp;= left( begin{array}{rrr} mathit{n_{x}}^{2} + { left( mathit{n_{y}}^{2} + mathit{n_{z}}^{2} right)} cos left(a right) &amp; - mathit{n_{x}} mathit{n_{y}} cos left(a right) + mathit{n_{x}} mathit{n_{y}} - { left( mathit{n_{z}}^{3} + { left( mathit{n_{x}}^{2} + mathit{n_{y}}^{2} right)} mathit{n_{z}} right)} sin left(a right) &amp; - mathit{n_{x}} mathit{n_{z}} cos left(a right) + mathit{n_{x}} mathit{n_{z}} + mathit{n_{y}} sin left(a right) - mathit{n_{x}} mathit{n_{y}} cos left(a right) + mathit{n_{x}} mathit{n_{y}} + { left( mathit{n_{z}}^{3} + { left( mathit{n_{x}}^{2} + mathit{n_{y}}^{2} right)} mathit{n_{z}} right)} sin left(a right) &amp; mathit{n_{y}}^{2} + { left( mathit{n_{x}}^{2} + mathit{n_{z}}^{2} right)} cos left(a right) &amp; - mathit{n_{y}} mathit{n_{z}} cos left(a right) + mathit{n_{y}} mathit{n_{z}} - mathit{n_{x}} sin left(a right) - mathit{n_{x}} mathit{n_{z}} cos left(a right) + mathit{n_{x}} mathit{n_{z}} - { left( mathit{n_{x}}^{2} mathit{n_{y}} + mathit{n_{y}}^{3} + mathit{n_{y}} mathit{n_{z}}^{2} right)} sin left(a right) &amp; - mathit{n_{y}} mathit{n_{z}} cos left(a right) + mathit{n_{y}} mathit{n_{z}} + { left( mathit{n_{x}}^{3} + mathit{n_{x}} mathit{n_{y}}^{2} + mathit{n_{x}} mathit{n_{z}}^{2} right)} sin left(a right) &amp; mathit{n_{z}}^{2} + { left( mathit{n_{x}}^{2} + mathit{n_{y}}^{2} right)} cos left(a right) end{array} right) &amp;= left( begin{array}{rrr} cos left(a right) + mathit{n_{x}}^{2} left(1- cos left(a right) right) &amp; mathit{n_{x}} mathit{n_{y}} left(1 - cos left(a right) right) - mathit{n_{z}} sin left(a right) &amp; mathit{n_{x}} mathit{n_{z}} left( 1 - cos left(a right) right) + mathit{n_{y}} sin left(a right) mathit{n_{x}} mathit{n_{y}} left( 1 - cos left(a right) right) + mathit{n_{z}} sin left(a right) &amp; cos left(a right) + mathit{n_{y}}^{2} left( 1- cos left(a right) right) &amp; mathit{n_{y}} mathit{n_{z}} left( 1- cos left(a right) right) - mathit{n_{x}} sin left(a right) mathit{n_{x}} mathit{n_{z}} left(1- cos left(a right) right) - mathit{n_{y}} sin left(a right) &amp; mathit{n_{y}} mathit{n_{z}} left(1- cos left(a right) right) + mathit{n_{x}} sin left(a right) &amp; cos left(a right) + mathit{n_{z}}^{2} left( 1- cos left(a right) right) end{array} right) end{aligned}Ra​R​=⎝⎜⎜⎜⎜⎜⎛​cos(a)sin(a)0​−sin(a)cos(a)0​001​⎠⎟⎟⎟⎟⎟⎞​=P∗Ra​∗PT=⎝⎜⎜⎜⎜⎜⎛​nx​2+(ny​2+nz​2)cos(a)−nx​ny​cos(a)+nx​ny​+(nz​3+(nx​2+ny​2)nz​)sin(a)−nx​nz​cos(a)+nx​nz​−(nx​2ny​+ny​3+ny​nz​2)sin(a)​−nx​ny​cos(a)+nx​ny​−(nz​3+(nx​2+ny​2)nz​)sin(a)ny​2+(nx​2+nz​2)cos(a)−ny​nz​cos(a)+ny​nz​+(nx​3+nx​ny​2+nx​nz​2)sin(a)​−nx​nz​cos(a)+nx​nz​+ny​sin(a)−ny​nz​cos(a)+ny​nz​−nx​sin(a)nz​2+(nx​2+ny​2)cos(a)​⎠⎟⎟⎟⎟⎟⎞​=⎝⎜⎜⎜⎜⎜⎛​cos(a)+nx​2(1−cos(a))nx​ny​(1−cos(a))+nz​sin(a)nx​nz​(1−cos(a))−ny​sin(a)​nx​ny​(1−cos(a))−nz​sin(a)cos(a)+ny​2(1−cos(a))ny​nz​(1−cos(a))+nx​sin(a)​nx​nz​(1−cos(a))+ny​sin(a)ny​nz​(1−cos(a))−nx​sin(a)cos(a)+nz​2(1−cos(a))​⎠⎟⎟⎟⎟⎟⎞​​ .",
            "url": "https://lab.ar90n.net/math/geometry/2020/06/27/linear-algebra-in-3d-coordinates.html",
            "relUrl": "/math/geometry/2020/06/27/linear-algebra-in-3d-coordinates.html",
            "date": " • Jun 27, 2020"
        }
        
    
  
    
        ,"post15": {
            "title": "5行で書くポアソンブレンディング",
            "content": "はじめに . 画像の滑らかな合成アルゴリズムにポアソンブレンディング(Poisson Image Editting)があります．これは，ポアソン方程式を解くことで元の勾配を保ちながら，境界部分が連続となる合成画像を推定するというものです． ネットを調べると，ポアソン方程式の計算にはSOR法やマルチグリッド法などを実装した高速な連立方程式ソルバを利用することが多いようです．しかしながら，外部のソルバを利用するとプロジェクトの規模が大きくなってしまいます．また，外部のソルバを利用せず，上述のアルゴリズムを自前で実装することは非常に困難な作業です．そこで，ヤコビ法をラプラシアンフィルタで記述し実装を簡略化しました． . やったこと . ラプラシアンフィルタを使用してヤコビ法を記述 | ポアソンブレンディングを５行で実装 | プロジェクトをGithubに作成 | . ポアソン方程式をラプラシアンフィルタで記述する . 参考記事によると，座標$p$における画素値$f_p$は以下の式で求められます． . fp=∑q∈Nfq+4gq−∑q∈Ngq4f_p = frac{ sum_{q in N} f_q + 4 g_{q} - sum_{q in N} g_q}{4}fp​=4∑q∈N​fq​+4gq​−∑q∈N​gq​​ . ここで，ヤコビ法によって$f_p$を求めます．$k$回目のイテレーションにおける座標$p$における画素値を$f_{p}^{k}$とします．すると，$f_{p}^{k}$は以下のように表記することができます． . fpk+1=∑q∈Nfqk+4gp−∑q∈Ngq4=4fpk−4fpk+∑q∈Nfqk+4gp−∑q∈Ngq4=fpk+−4(fpk−gp)+∑q∈Nfqk−gq4=fpk+14Δp(f−g) begin{aligned} f_{p}^{k+1} &amp;= frac{ sum_{q in N} f_{q}^{k} + 4 g_{p} - sum_{q in N} g_{q}}{4} &amp;= frac{4f_{p}^{k} -4 f_{p}^{k} + sum_{q in N} f_{q}^{k} + 4 g_{p} - sum_{q in N} g_q}{4} &amp;= f_{p}^{k} + frac{-4 (f_{p}^{k} - g_{p}) + sum_{q in N} f_{q}^{k} - g_q}{4} &amp;= f_{p}^{k} + frac{1}{4} Delta_{p} left(f - g right) end{aligned}fpk+1​​=4∑q∈N​fqk​+4gp​−∑q∈N​gq​​=44fpk​−4fpk​+∑q∈N​fqk​+4gp​−∑q∈N​gq​​=fpk​+4−4(fpk​−gp​)+∑q∈N​fqk​−gq​​=fpk​+41​Δp​(f−g)​ . 以上の結果より，注目領域に$ frac{1}{4} Delta_{p} left(f - g right)$を加算していくことで合成を行います． $ Delta_{p}$は座標$p$におけるラプラシアンを表します．以下にscipyを用いで実装したコードを示します．関数の引数はそれぞれ，target_imgが合成先画像，src_imgが合成元画像, mask_imgが合成領域マスク, iterが反復処理の回数をそれぞれ表します．コードサイズを5行に抑えるため，省いた処理（入力のバリデーション，反復処理の打ち切り）や冗長な処理（target_imgとsrc_imgとの差分を毎ループ計算している）がありますが，アルゴリズムのエッセンスは十分表現できていると思います． . 5行で実装 . from scipy.ndimage import laplace def poisson_blend(target_img, src_img, mask_img, iter: int = 1024): for _ in range(iter): target_img = target_img + 0.25 * mask_img * laplace(target_img - src_img) return target_img.clip(0, 1) . poisson_blendの入力と出力との関係を以下の図に示します．以下の図は，左側から合成元画像(src_img)，合成領域マスク(mask_img)，合成先画像(target_img)，合成画像を表します．境界領域が滑らかに合成されていることが確認できます． . . 上記の関数に加え，結果確認用のノートブックなどを追加したリポジトリを作成しました．よろしければ，こちらも参考にしてください. . 参考 . Poisson Image Editing | ar90n/poisson-blending-in-5lines | .",
            "url": "https://lab.ar90n.net/imageprocessing/python/2020/05/31/poisson-blending-in-5-lines.html",
            "relUrl": "/imageprocessing/python/2020/05/31/poisson-blending-in-5-lines.html",
            "date": " • May 31, 2020"
        }
        
    
  
    
        ,"post16": {
            "title": "Raspberry Pi 4 + k3s + Rayで分散処理を試す",
            "content": "はじめに . Raspberry Pi 4+k3s+rayでクラスタを作成して，分散処理の実験を行います．Raspberry Pi 4 には事前にUbuntu 20.04を導入しておきます． . cgroupの有効化 . 残念ながら，このcgroupの設定が何故必要なのかを理解できていません．しかしながら，Webで調べた限りでは，必要そうなので設定することにします．（設定しない場合はどうなるかを試してはいません） . SDカードをホストマシンにマウントして以下のコマンド実行します．以下の例では，/Vlumes/system-bootにSDカードがマウントされています．マウントポイントについては，環境に応じて適切に書き換えてください． . $ sed -i -e &#39;s/$/ cgroup_memory=1 cgroup_enable=memory cgroup_enable=cpuset/&#39; /Volumes/system-boot/cmdline.txt . 修正したSDカードを用いてシステムを起動します．その後，以下のコマンドで設定の反映を確認できます． . $ cat /proc/cgroups #subsys_name hierarchy num_cgroups enabled cpuset 5 10 1 cpu 4 98 1 cpuacct 4 98 1 blkio 8 98 1 memory 2 147 1 devices 11 98 1 freezer 9 11 1 net_cls 6 10 1 perf_event 7 10 1 net_prio 6 10 1 pids 10 106 1 rdma 3 1 1 . k3sの導入 . リポジトリの手順に従います．注意が必要な点は，マスターノードとワーカーノードとで導入方法が異なる点です．ここでハマらなければ，さくっと導入できると思います．今回，以下の様にマスターノードx1，ワーカーノードx3でk3sクラスタを構成しました． . $ kubectl get nodes NAME STATUS ROLES AGE VERSION k3s-node3 Ready worker 3d12h v1.18.2+k3s1 k3s-node2 Ready worker 3d12h v1.18.2+k3s1 k3s-node1 Ready worker 3d12h v1.18.2+k3s1 k3s-master Ready master 3d18h v1.18.2+k3s1 . rayクラスタのデプロイ . こちらも公式の手順に従います．しかしながら，こちらで使用しているDockerイメージはamd64向けに作成された物であり，aarch64環境では動作しません．そこで，ほぼ等価なイメージをaarch64向けに作成しました．今回は，このイメージを用いてクラスタを作成します．具体的には，ray-cluster.yamlを以下の様に修正します． . diff --git a/doc/kubernetes/ray-cluster.yaml b/doc/kubernetes/ray-cluster.yaml index 853f9dfb2..0563c934f 100644 a/doc/kubernetes/ray-cluster.yaml +++ b/doc/kubernetes/ray-cluster.yaml @@ -59,7 +59,7 @@ spec: medium: Memory containers: - name: ray-head - image: rayproject/autoscaler + image: ar90n/autoscaler-py37 imagePullPolicy: Always command: [ &quot;/bin/bash&quot;, &quot;-c&quot;, &quot;--&quot; ] args: @@ -120,7 +120,7 @@ spec: medium: Memory containers: - name: ray-worker - image: rayproject/autoscaler + image: ar90n/autoscaler-py37 imagePullPolicy: Always command: [&quot;/bin/bash&quot;, &quot;-c&quot;, &quot;--&quot;] args: . 以下のようにコンテナをデプロイします． . $ kubectl create -f ray/doc/kubernetes/ray-namespace.yaml namespace/ray created $ kubectl apply -f ray/doc/kubernetes/ray-cluster.yaml service/ray-head created deployment.apps/ray-head created deployment.apps/ray-worker created $ kubectl -n ray get pods NAME READY STATUS RESTARTS AGE ray-head-7957ff48b6-tj6z2 1/1 Running 0 118s ray-worker-7574c9d77-bs4dx 1/1 Running 0 118s ray-worker-7574c9d77-2868n 1/1 Running 1 118s ray-worker-7574c9d77-x48m7 1/1 Running 0 118s . クラスタの作成が完了したので，テストプログラムを実行します．こちらも公式の手順に従い，example.pyを実行します． . $ kubectl -n ray cp ray/doc/kubernetes/example.py ray-head-7957ff48b6-tj6z2:/example.py $ kubectl -n ray exec ray-head-7957ff48b6-tj6z2 -- python example.py 2020-05-24 14:13:54,824 WARNING worker.py:809 -- When connecting to an existing cluster, _internal_config must match the cluster&#39;s _internal_config. Iteration 0 Counter({(&#39;ray-worker-7574c9d77-2868n&#39;, &#39;ray-head-7957ff48b6-tj6z2&#39;): 9, (&#39;ray-worker-7574c9d77-x48m7&#39;, &#39;ray-worker-7574c9d77-bs4dx&#39;): 9, (&#39;ray-head-7957ff48b6-tj6z2&#39;, &#39;ray-worker-7574c9d77-bs4dx&#39;): 9, (&#39;ray-worker-7574c9d77-2868n&#39;, &#39;ray-worker-7574c9d77-bs4dx&#39;): 9, (&#39;ray-head-7957ff48b6-tj6z2&#39;, &#39;ray-worker-7574c9d77-x48m7&#39;): 8, (&#39;ray-worker-7574c9d77-bs4dx&#39;, &#39;ray-worker-7574c9d77-bs4dx&#39;): 8, (&#39;ray-head-7957ff48b6-tj6z2&#39;, &#39;ray-head-7957ff48b6-tj6z2&#39;): 7, (&#39;ray-worker-7574c9d77-bs4dx&#39;, &#39;ray-head-7957ff48b6-tj6z2&#39;): 7, (&#39;ray-worker-7574c9d77-x48m7&#39;, &#39;ray-head-7957ff48b6-tj6z2&#39;): 6, (&#39;ray-head-7957ff48b6-tj6z2&#39;, &#39;ray-worker-7574c9d77-2868n&#39;): 6, (&#39;ray-worker-7574c9d77-2868n&#39;, &#39;ray-worker-7574c9d77-x48m7&#39;): 5, (&#39;ray-worker-7574c9d77-bs4dx&#39;, &#39;ray-worker-7574c9d77-2868n&#39;): 5, (&#39;ray-worker-7574c9d77-x48m7&#39;, &#39;ray-worker-7574c9d77-2868n&#39;): 4, (&#39;ray-worker-7574c9d77-x48m7&#39;, &#39;ray-worker-7574c9d77-x48m7&#39;): 4, (&#39;ray-worker-7574c9d77-2868n&#39;, &#39;ray-worker-7574c9d77-2868n&#39;): 3, (&#39;ray-worker-7574c9d77-bs4dx&#39;, &#39;ray-worker-7574c9d77-x48m7&#39;): 1}) Iteration 1 Counter({(&#39;ray-head-7957ff48b6-tj6z2&#39;, &#39;ray-worker-7574c9d77-bs4dx&#39;): 12, (&#39;ray-head-7957ff48b6-tj6z2&#39;, &#39;ray-head-7957ff48b6-tj6z2&#39;): 10, (&#39;ray-worker-7574c9d77-x48m7&#39;, &#39;ray-worker-7574c9d77-bs4dx&#39;): 9, (&#39;ray-worker-7574c9d77-bs4dx&#39;, &#39;ray-worker-7574c9d77-bs4dx&#39;): 9, (&#39;ray-worker-7574c9d77-x48m7&#39;, &#39;ray-worker-7574c9d77-2868n&#39;): 8, (&#39;ray-worker-7574c9d77-bs4dx&#39;, &#39;ray-head-7957ff48b6-tj6z2&#39;): 7, (&#39;ray-worker-7574c9d77-bs4dx&#39;, &#39;ray-worker-7574c9d77-x48m7&#39;): 7, (&#39;ray-worker-7574c9d77-2868n&#39;, &#39;ray-head-7957ff48b6-tj6z2&#39;): 6, (&#39;ray-worker-7574c9d77-2868n&#39;, &#39;ray-worker-7574c9d77-x48m7&#39;): 6, (&#39;ray-head-7957ff48b6-tj6z2&#39;, &#39;ray-worker-7574c9d77-2868n&#39;): 5, (&#39;ray-worker-7574c9d77-x48m7&#39;, &#39;ray-head-7957ff48b6-tj6z2&#39;): 5, (&#39;ray-worker-7574c9d77-x48m7&#39;, &#39;ray-worker-7574c9d77-x48m7&#39;): 4, (&#39;ray-head-7957ff48b6-tj6z2&#39;, &#39;ray-worker-7574c9d77-x48m7&#39;): 4, (&#39;ray-worker-7574c9d77-2868n&#39;, &#39;ray-worker-7574c9d77-bs4dx&#39;): 4, (&#39;ray-worker-7574c9d77-bs4dx&#39;, &#39;ray-worker-7574c9d77-2868n&#39;): 2, (&#39;ray-worker-7574c9d77-2868n&#39;, &#39;ray-worker-7574c9d77-2868n&#39;): 2}) Iteration 2 Counter({(&#39;ray-worker-7574c9d77-x48m7&#39;, &#39;ray-head-7957ff48b6-tj6z2&#39;): 12, (&#39;ray-head-7957ff48b6-tj6z2&#39;, &#39;ray-worker-7574c9d77-bs4dx&#39;): 11, (&#39;ray-worker-7574c9d77-2868n&#39;, &#39;ray-worker-7574c9d77-x48m7&#39;): 10, (&#39;ray-worker-7574c9d77-bs4dx&#39;, &#39;ray-head-7957ff48b6-tj6z2&#39;): 9, (&#39;ray-head-7957ff48b6-tj6z2&#39;, &#39;ray-worker-7574c9d77-x48m7&#39;): 8, (&#39;ray-head-7957ff48b6-tj6z2&#39;, &#39;ray-head-7957ff48b6-tj6z2&#39;): 8, (&#39;ray-worker-7574c9d77-bs4dx&#39;, &#39;ray-worker-7574c9d77-bs4dx&#39;): 6, (&#39;ray-worker-7574c9d77-2868n&#39;, &#39;ray-worker-7574c9d77-bs4dx&#39;): 5, (&#39;ray-worker-7574c9d77-x48m7&#39;, &#39;ray-worker-7574c9d77-2868n&#39;): 5, (&#39;ray-worker-7574c9d77-bs4dx&#39;, &#39;ray-worker-7574c9d77-x48m7&#39;): 5, (&#39;ray-worker-7574c9d77-2868n&#39;, &#39;ray-head-7957ff48b6-tj6z2&#39;): 4, (&#39;ray-worker-7574c9d77-2868n&#39;, &#39;ray-worker-7574c9d77-2868n&#39;): 4, (&#39;ray-worker-7574c9d77-x48m7&#39;, &#39;ray-worker-7574c9d77-x48m7&#39;): 4, (&#39;ray-worker-7574c9d77-bs4dx&#39;, &#39;ray-worker-7574c9d77-2868n&#39;): 4, (&#39;ray-head-7957ff48b6-tj6z2&#39;, &#39;ray-worker-7574c9d77-2868n&#39;): 3, (&#39;ray-worker-7574c9d77-x48m7&#39;, &#39;ray-worker-7574c9d77-bs4dx&#39;): 2}) Iteration 3 Counter({(&#39;ray-head-7957ff48b6-tj6z2&#39;, &#39;ray-head-7957ff48b6-tj6z2&#39;): 13, (&#39;ray-head-7957ff48b6-tj6z2&#39;, &#39;ray-worker-7574c9d77-bs4dx&#39;): 10, (&#39;ray-worker-7574c9d77-bs4dx&#39;, &#39;ray-worker-7574c9d77-bs4dx&#39;): 8, (&#39;ray-worker-7574c9d77-bs4dx&#39;, &#39;ray-worker-7574c9d77-2868n&#39;): 8, (&#39;ray-worker-7574c9d77-x48m7&#39;, &#39;ray-worker-7574c9d77-2868n&#39;): 7, (&#39;ray-worker-7574c9d77-x48m7&#39;, &#39;ray-worker-7574c9d77-bs4dx&#39;): 7, (&#39;ray-worker-7574c9d77-x48m7&#39;, &#39;ray-worker-7574c9d77-x48m7&#39;): 6, (&#39;ray-worker-7574c9d77-2868n&#39;, &#39;ray-worker-7574c9d77-2868n&#39;): 6, (&#39;ray-worker-7574c9d77-2868n&#39;, &#39;ray-worker-7574c9d77-x48m7&#39;): 6, (&#39;ray-worker-7574c9d77-x48m7&#39;, &#39;ray-head-7957ff48b6-tj6z2&#39;): 5, (&#39;ray-worker-7574c9d77-bs4dx&#39;, &#39;ray-worker-7574c9d77-x48m7&#39;): 5, (&#39;ray-head-7957ff48b6-tj6z2&#39;, &#39;ray-worker-7574c9d77-2868n&#39;): 5, (&#39;ray-worker-7574c9d77-2868n&#39;, &#39;ray-worker-7574c9d77-bs4dx&#39;): 4, (&#39;ray-worker-7574c9d77-bs4dx&#39;, &#39;ray-head-7957ff48b6-tj6z2&#39;): 4, (&#39;ray-head-7957ff48b6-tj6z2&#39;, &#39;ray-worker-7574c9d77-x48m7&#39;): 3, (&#39;ray-worker-7574c9d77-2868n&#39;, &#39;ray-head-7957ff48b6-tj6z2&#39;): 3}) Iteration 4 Counter({(&#39;ray-worker-7574c9d77-2868n&#39;, &#39;ray-worker-7574c9d77-bs4dx&#39;): 11, (&#39;ray-head-7957ff48b6-tj6z2&#39;, &#39;ray-worker-7574c9d77-bs4dx&#39;): 11, (&#39;ray-worker-7574c9d77-x48m7&#39;, &#39;ray-head-7957ff48b6-tj6z2&#39;): 10, (&#39;ray-worker-7574c9d77-bs4dx&#39;, &#39;ray-worker-7574c9d77-2868n&#39;): 9, (&#39;ray-head-7957ff48b6-tj6z2&#39;, &#39;ray-worker-7574c9d77-x48m7&#39;): 9, (&#39;ray-worker-7574c9d77-2868n&#39;, &#39;ray-worker-7574c9d77-x48m7&#39;): 7, (&#39;ray-head-7957ff48b6-tj6z2&#39;, &#39;ray-head-7957ff48b6-tj6z2&#39;): 7, (&#39;ray-worker-7574c9d77-bs4dx&#39;, &#39;ray-worker-7574c9d77-x48m7&#39;): 7, (&#39;ray-head-7957ff48b6-tj6z2&#39;, &#39;ray-worker-7574c9d77-2868n&#39;): 6, (&#39;ray-worker-7574c9d77-bs4dx&#39;, &#39;ray-worker-7574c9d77-bs4dx&#39;): 6, (&#39;ray-worker-7574c9d77-bs4dx&#39;, &#39;ray-head-7957ff48b6-tj6z2&#39;): 5, (&#39;ray-worker-7574c9d77-2868n&#39;, &#39;ray-head-7957ff48b6-tj6z2&#39;): 3, (&#39;ray-worker-7574c9d77-x48m7&#39;, &#39;ray-worker-7574c9d77-bs4dx&#39;): 3, (&#39;ray-worker-7574c9d77-2868n&#39;, &#39;ray-worker-7574c9d77-2868n&#39;): 2, (&#39;ray-worker-7574c9d77-x48m7&#39;, &#39;ray-worker-7574c9d77-2868n&#39;): 2, (&#39;ray-worker-7574c9d77-x48m7&#39;, &#39;ray-worker-7574c9d77-x48m7&#39;): 2}) Iteration 5 Counter({(&#39;ray-worker-7574c9d77-bs4dx&#39;, &#39;ray-head-7957ff48b6-tj6z2&#39;): 11, (&#39;ray-worker-7574c9d77-x48m7&#39;, &#39;ray-head-7957ff48b6-tj6z2&#39;): 11, (&#39;ray-head-7957ff48b6-tj6z2&#39;, &#39;ray-head-7957ff48b6-tj6z2&#39;): 9, (&#39;ray-worker-7574c9d77-bs4dx&#39;, &#39;ray-worker-7574c9d77-bs4dx&#39;): 9, (&#39;ray-head-7957ff48b6-tj6z2&#39;, &#39;ray-worker-7574c9d77-bs4dx&#39;): 8, (&#39;ray-head-7957ff48b6-tj6z2&#39;, &#39;ray-worker-7574c9d77-2868n&#39;): 8, (&#39;ray-worker-7574c9d77-2868n&#39;, &#39;ray-head-7957ff48b6-tj6z2&#39;): 8, (&#39;ray-worker-7574c9d77-bs4dx&#39;, &#39;ray-worker-7574c9d77-x48m7&#39;): 7, (&#39;ray-worker-7574c9d77-2868n&#39;, &#39;ray-worker-7574c9d77-bs4dx&#39;): 7, (&#39;ray-head-7957ff48b6-tj6z2&#39;, &#39;ray-worker-7574c9d77-x48m7&#39;): 5, (&#39;ray-worker-7574c9d77-x48m7&#39;, &#39;ray-worker-7574c9d77-x48m7&#39;): 5, (&#39;ray-worker-7574c9d77-x48m7&#39;, &#39;ray-worker-7574c9d77-2868n&#39;): 4, (&#39;ray-worker-7574c9d77-x48m7&#39;, &#39;ray-worker-7574c9d77-bs4dx&#39;): 3, (&#39;ray-worker-7574c9d77-bs4dx&#39;, &#39;ray-worker-7574c9d77-2868n&#39;): 2, (&#39;ray-worker-7574c9d77-2868n&#39;, &#39;ray-worker-7574c9d77-2868n&#39;): 2, (&#39;ray-worker-7574c9d77-2868n&#39;, &#39;ray-worker-7574c9d77-x48m7&#39;): 1}) Iteration 6 Counter({(&#39;ray-head-7957ff48b6-tj6z2&#39;, &#39;ray-worker-7574c9d77-bs4dx&#39;): 12, (&#39;ray-worker-7574c9d77-2868n&#39;, &#39;ray-worker-7574c9d77-bs4dx&#39;): 10, (&#39;ray-head-7957ff48b6-tj6z2&#39;, &#39;ray-head-7957ff48b6-tj6z2&#39;): 9, (&#39;ray-worker-7574c9d77-bs4dx&#39;, &#39;ray-head-7957ff48b6-tj6z2&#39;): 9, (&#39;ray-head-7957ff48b6-tj6z2&#39;, &#39;ray-worker-7574c9d77-2868n&#39;): 7, (&#39;ray-worker-7574c9d77-x48m7&#39;, &#39;ray-worker-7574c9d77-bs4dx&#39;): 7, (&#39;ray-head-7957ff48b6-tj6z2&#39;, &#39;ray-worker-7574c9d77-x48m7&#39;): 6, (&#39;ray-worker-7574c9d77-bs4dx&#39;, &#39;ray-worker-7574c9d77-x48m7&#39;): 6, (&#39;ray-worker-7574c9d77-x48m7&#39;, &#39;ray-worker-7574c9d77-2868n&#39;): 6, (&#39;ray-worker-7574c9d77-2868n&#39;, &#39;ray-worker-7574c9d77-x48m7&#39;): 5, (&#39;ray-worker-7574c9d77-bs4dx&#39;, &#39;ray-worker-7574c9d77-2868n&#39;): 5, (&#39;ray-worker-7574c9d77-x48m7&#39;, &#39;ray-worker-7574c9d77-x48m7&#39;): 4, (&#39;ray-worker-7574c9d77-bs4dx&#39;, &#39;ray-worker-7574c9d77-bs4dx&#39;): 4, (&#39;ray-worker-7574c9d77-2868n&#39;, &#39;ray-head-7957ff48b6-tj6z2&#39;): 4, (&#39;ray-worker-7574c9d77-x48m7&#39;, &#39;ray-head-7957ff48b6-tj6z2&#39;): 4, (&#39;ray-worker-7574c9d77-2868n&#39;, &#39;ray-worker-7574c9d77-2868n&#39;): 2}) Iteration 7 Counter({(&#39;ray-head-7957ff48b6-tj6z2&#39;, &#39;ray-worker-7574c9d77-bs4dx&#39;): 12, (&#39;ray-head-7957ff48b6-tj6z2&#39;, &#39;ray-head-7957ff48b6-tj6z2&#39;): 10, (&#39;ray-head-7957ff48b6-tj6z2&#39;, &#39;ray-worker-7574c9d77-x48m7&#39;): 9, (&#39;ray-worker-7574c9d77-2868n&#39;, &#39;ray-head-7957ff48b6-tj6z2&#39;): 8, (&#39;ray-worker-7574c9d77-x48m7&#39;, &#39;ray-head-7957ff48b6-tj6z2&#39;): 7, (&#39;ray-worker-7574c9d77-x48m7&#39;, &#39;ray-worker-7574c9d77-bs4dx&#39;): 7, (&#39;ray-worker-7574c9d77-bs4dx&#39;, &#39;ray-worker-7574c9d77-bs4dx&#39;): 7, (&#39;ray-worker-7574c9d77-bs4dx&#39;, &#39;ray-head-7957ff48b6-tj6z2&#39;): 7, (&#39;ray-worker-7574c9d77-bs4dx&#39;, &#39;ray-worker-7574c9d77-2868n&#39;): 5, (&#39;ray-worker-7574c9d77-2868n&#39;, &#39;ray-worker-7574c9d77-x48m7&#39;): 5, (&#39;ray-worker-7574c9d77-bs4dx&#39;, &#39;ray-worker-7574c9d77-x48m7&#39;): 5, (&#39;ray-head-7957ff48b6-tj6z2&#39;, &#39;ray-worker-7574c9d77-2868n&#39;): 4, (&#39;ray-worker-7574c9d77-2868n&#39;, &#39;ray-worker-7574c9d77-2868n&#39;): 4, (&#39;ray-worker-7574c9d77-x48m7&#39;, &#39;ray-worker-7574c9d77-2868n&#39;): 4, (&#39;ray-worker-7574c9d77-x48m7&#39;, &#39;ray-worker-7574c9d77-x48m7&#39;): 3, (&#39;ray-worker-7574c9d77-2868n&#39;, &#39;ray-worker-7574c9d77-bs4dx&#39;): 3}) Iteration 8 Counter({(&#39;ray-head-7957ff48b6-tj6z2&#39;, &#39;ray-worker-7574c9d77-bs4dx&#39;): 10, (&#39;ray-worker-7574c9d77-2868n&#39;, &#39;ray-worker-7574c9d77-x48m7&#39;): 10, (&#39;ray-worker-7574c9d77-bs4dx&#39;, &#39;ray-head-7957ff48b6-tj6z2&#39;): 10, (&#39;ray-worker-7574c9d77-2868n&#39;, &#39;ray-worker-7574c9d77-bs4dx&#39;): 9, (&#39;ray-head-7957ff48b6-tj6z2&#39;, &#39;ray-head-7957ff48b6-tj6z2&#39;): 9, (&#39;ray-head-7957ff48b6-tj6z2&#39;, &#39;ray-worker-7574c9d77-x48m7&#39;): 8, (&#39;ray-worker-7574c9d77-x48m7&#39;, &#39;ray-worker-7574c9d77-bs4dx&#39;): 7, (&#39;ray-worker-7574c9d77-bs4dx&#39;, &#39;ray-worker-7574c9d77-bs4dx&#39;): 7, (&#39;ray-worker-7574c9d77-x48m7&#39;, &#39;ray-worker-7574c9d77-2868n&#39;): 6, (&#39;ray-worker-7574c9d77-bs4dx&#39;, &#39;ray-worker-7574c9d77-x48m7&#39;): 6, (&#39;ray-worker-7574c9d77-x48m7&#39;, &#39;ray-head-7957ff48b6-tj6z2&#39;): 4, (&#39;ray-worker-7574c9d77-2868n&#39;, &#39;ray-head-7957ff48b6-tj6z2&#39;): 4, (&#39;ray-head-7957ff48b6-tj6z2&#39;, &#39;ray-worker-7574c9d77-2868n&#39;): 3, (&#39;ray-worker-7574c9d77-2868n&#39;, &#39;ray-worker-7574c9d77-2868n&#39;): 3, (&#39;ray-worker-7574c9d77-x48m7&#39;, &#39;ray-worker-7574c9d77-x48m7&#39;): 2, (&#39;ray-worker-7574c9d77-bs4dx&#39;, &#39;ray-worker-7574c9d77-2868n&#39;): 2}) Iteration 9 Counter({(&#39;ray-worker-7574c9d77-bs4dx&#39;, &#39;ray-worker-7574c9d77-bs4dx&#39;): 10, (&#39;ray-head-7957ff48b6-tj6z2&#39;, &#39;ray-worker-7574c9d77-bs4dx&#39;): 9, (&#39;ray-head-7957ff48b6-tj6z2&#39;, &#39;ray-worker-7574c9d77-2868n&#39;): 9, (&#39;ray-worker-7574c9d77-bs4dx&#39;, &#39;ray-head-7957ff48b6-tj6z2&#39;): 8, (&#39;ray-head-7957ff48b6-tj6z2&#39;, &#39;ray-worker-7574c9d77-x48m7&#39;): 8, (&#39;ray-worker-7574c9d77-bs4dx&#39;, &#39;ray-worker-7574c9d77-2868n&#39;): 7, (&#39;ray-worker-7574c9d77-x48m7&#39;, &#39;ray-head-7957ff48b6-tj6z2&#39;): 7, (&#39;ray-worker-7574c9d77-bs4dx&#39;, &#39;ray-worker-7574c9d77-x48m7&#39;): 6, (&#39;ray-head-7957ff48b6-tj6z2&#39;, &#39;ray-head-7957ff48b6-tj6z2&#39;): 6, (&#39;ray-worker-7574c9d77-2868n&#39;, &#39;ray-head-7957ff48b6-tj6z2&#39;): 6, (&#39;ray-worker-7574c9d77-2868n&#39;, &#39;ray-worker-7574c9d77-bs4dx&#39;): 5, (&#39;ray-worker-7574c9d77-x48m7&#39;, &#39;ray-worker-7574c9d77-x48m7&#39;): 4, (&#39;ray-worker-7574c9d77-2868n&#39;, &#39;ray-worker-7574c9d77-x48m7&#39;): 4, (&#39;ray-worker-7574c9d77-2868n&#39;, &#39;ray-worker-7574c9d77-2868n&#39;): 4, (&#39;ray-worker-7574c9d77-x48m7&#39;, &#39;ray-worker-7574c9d77-bs4dx&#39;): 4, (&#39;ray-worker-7574c9d77-x48m7&#39;, &#39;ray-worker-7574c9d77-2868n&#39;): 3}) Success! . ベンチマーク . 最後に，作成したクラスタのベンチマークとして，マンデルブロ集合の描画時間を計測します．マンデルブロ集合の描画には以下のコードを用います．画像全体をn_x_grids x n_y_grids個の領域に区切り，各領域毎に並行処理します． . #!/usr/bin/env python import numpy as np from numba import njit import itertools import os import ray import matplotlib.pyplot as plt from timeit import timeit if (os.environ.get(&quot;RAY_HEAD_SERVICE_HOST&quot;) is None): ray.init() else: redis_host = os.environ[&quot;RAY_HEAD_SERVICE_HOST&quot;] ray.init(address=redis_host + &quot;:6379&quot;) n_x_grids = int(os.environ.get(&quot;X_GRIDS&quot;, 32)) n_y_grids = int(os.environ.get(&quot;Y_GRIDS&quot;, 32)) grid_width = int(os.environ.get(&quot;GRID_WIDTH&quot;, 100)) grid_height = int(os.environ.get(&quot;GRID_HEIGHT&quot;, 100)) def grid_range(begin, end, n_grids): ih, it = itertools.tee(np.linspace(begin, end, n_grids + 1)) next(it) return ((h,t) for h,t in zip(ih, it)) @ray.remote def mandelbrot(c, n = 32, th = 200): z = 1j * np.zeros(c.shape) r = np.zeros(c.shape) for i in range(n): mask = np.abs(z) &lt;= th z += (z * z + c - z) * mask.astype(np.int) r[mask] = i # make smooth return r - np.log2(np.log2(np.abs(z) + 1)) def rendering(n_xg, n_yg, gw, gh): res = [] xs = grid_range(-2, 1, n_xg) ys = grid_range(-1, 1, n_yg) for ((xb, xe), (yb, ye)) in itertools.product(xs, ys): x, y = np.meshgrid(np.linspace(xb, xe, gw), np.linspace(yb, ye, gh)) c = x + 1j * y res.append(mandelbrot.remote(c)) res = ray.get(res) return np.concatenate(np.concatenate(np.array(res).reshape(n_yg, n_xg, gh, gw), axis=2),axis=0) benchmark = timeit(lambda: rendering(n_x_grids, n_y_grids, grid_width, grid_height), number=8) / 8 print(f&quot;time: {benchmark}&quot;) img = rendering(n_x_grids, n_y_grids, grid_width, grid_height) plt.figure(dpi=200) plt.imshow(img, cmap=&#39;rainbow&#39;, interpolation=&#39;bilinear&#39;, extent=[-2, 1, -1, 1]) plt.xticks(color=&#39;None&#39;) plt.yticks(color=&#39;None&#39;) plt.tick_params(length=0) plt.savefig(&#39;figure.png&#39;) . また，クラスタの設定も少しだけ修正します．各コンテナに割り当てるメモリの変更と，必要なパッケージをコンテナ起動時に追加します． . diff --git a/doc/kubernetes/ray-cluster.yaml b/doc/kubernetes/ray-cluster.yaml index 853f9dfb2..d2b2c9678 100644 a/doc/kubernetes/ray-cluster.yaml +++ b/doc/kubernetes/ray-cluster.yaml @@ -59,11 +59,11 @@ spec: medium: Memory containers: - name: ray-head - image: rayproject/autoscaler + image: ar90n/autoscaler-py37 imagePullPolicy: Always command: [ &quot;/bin/bash&quot;, &quot;-c&quot;, &quot;--&quot; ] args: - - &quot;ray start --head --node-ip-address=$MY_POD_IP --redis-port=6379 --redis-shard-ports=6380,6381 --num-cpus=$MY_CPU_REQUEST --object-manager-port=12345 --node-manager-port=12346 --block&quot; + - &quot;conda install -y -c numba numba &amp;&amp; conda install -y matplotlib &amp;&amp; ray start --head --node-ip-address=$MY_POD_IP --redis-port=6379 --redis-shard-ports=6380,6381 --num-cpus=$MY_CPU_REQUEST --object-manager-port=12345 --node-manager-port=12346 --block&quot; ports: - containerPort: 6379 # Redis port. - containerPort: 6380 # Redis port. @@ -120,11 +120,11 @@ spec: medium: Memory containers: - name: ray-worker - image: rayproject/autoscaler + image: ar90n/autoscaler-py37 imagePullPolicy: Always command: [&quot;/bin/bash&quot;, &quot;-c&quot;, &quot;--&quot;] args: - - &quot;ray start --node-ip-address=$MY_POD_IP --num-cpus=$MY_CPU_REQUEST --address=$RAY_HEAD_SERVICE_HOST:$RAY_HEAD_SERVICE_PORT_REDIS_PRIMARY --object-manager-port=12345 --node-manager-port=12346 --block&quot; + - &quot;conda install -y -c numba numba &amp;&amp; conda install -y matplotlib &amp;&amp; ray start --node-ip-address=$MY_POD_IP --num-cpus=$MY_CPU_REQUEST --address=$RAY_HEAD_SERVICE_HOST:$RAY_HEAD_SERVICE_PORT_REDIS_PRIMARY --object-manager-port=12345 --node-manager-port=12346 --block&quot; ports: - containerPort: 12345 # Ray internal communication. - containerPort: 12346 # Ray internal communication. @@ -147,4 +147,4 @@ spec: resources: requests: cpu: 100m - memory: 512Mi + memory: 1024Mi . 実行結果を以下に示します．無事に動作している様です． . $ kubectl -n ray exec ray-head-6785995666-m49kv -- python main.py 2020-05-24 14:57:57,849 WARNING worker.py:809 -- When connecting to an existing cluster, _internal_config must match the cluster&#39;s _internal_config. (pid=2799) main.py:36: RuntimeWarning: divide by zero encountered in log2 (pid=2799) return r - np.log2(np.log2(np.abs(z) + 1)) (pid=2780, ip=10.42.1.13) main.py:36: RuntimeWarning: divide by zero encountered in log2 (pid=2780, ip=10.42.4.25) main.py:36: RuntimeWarning: divide by zero encountered in log2 (pid=2783, ip=10.42.0.35) main.py:36: RuntimeWarning: divide by zero encountered in log2 time: 34.654623864378664 . . Rayのワーカーノードの数を変更すると以下の様に処理時間が変化しました． . ワーカーノード数 処理時間[s] . 0 | 45.09195340787119 | . 1 | 48.55051823974645 | . 2 | 38.57156975386897 | . 3 | 34.654623864378664 | . あまり安定のしない微妙な結果となりました．思った以上に並列化される部分意外にボトルネックがあったのかもしれません． . 参考 . Raspberry pi 4におけるK3Sクラスタ構築 | Ray | k3s | .",
            "url": "https://lab.ar90n.net/kubernetes/ray/python/distributed%20systems/2020/05/25/Ray-k3s-raspi4.html",
            "relUrl": "/kubernetes/ray/python/distributed%20systems/2020/05/25/Ray-k3s-raspi4.html",
            "date": " • May 25, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "都内でソフトウェアエンジニアをやっています． . 画像処理，Python，Web開発など広くポストしてます． . Name . 和田政弘 . GitHub . @ar90n . Twitter . @ar90n . Mail . argon.argon.argon@gmail.com . Skill . 画像処理 | 医療画像処理 | Python | C++ | Web | 組み込み | .",
          "url": "https://lab.ar90n.net/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://lab.ar90n.net/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

  
  

}